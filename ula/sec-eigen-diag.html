<!DOCTYPE html>
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2019-12-26T11:10:44-05:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Diagonalization, similarity, and powers of a matrix</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script src="https://sagecell.sagemath.org/embedded_sagecell.js"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']]
    },
    asciimath2jax: {
        ignoreClass: ".*",
        processClass: "has_am"
    },
    jax: ["input/AsciiMath"],
    extensions: ["asciimath2jax.js"],
    TeX: {
        extensions: ["extpfeil.js", "autobold.js", "https://pretextbook.org/js/lib/mathjaxknowl.js", ],
        // scrolling to fragment identifiers is controlled by other Javascript
        positionToHash: false,
        equationNumbers: { autoNumber: "none", useLabelIds: true, },
        TagSide: "right",
        TagIndent: ".8em",
    },
    // HTML-CSS output Jax to be dropped for MathJax 3.0
    "HTML-CSS": {
        scale: 88,
        mtextFontInherit: true,
    },
    CommonHTML: {
        scale: 88,
        mtextFontInherit: true,
    },
});
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML-full"></script><script>$(function () {
    // Make *any* div with class 'sagecell-sage' an executable Sage cell
    // Their results will be linked, only within language type
    sagecell.makeSagecell({inputLocation: 'div.sagecell-sage',
                           linked: true,
                           languages: ['sage'],
                           evalButtonText: 'Evaluate (Sage)'});
});
</script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.12/pretext.js"></script><script src="https://pretextbook.org/js/0.12/pretext_add_on.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/toc.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/setcolors.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.2/features.css" rel="stylesheet" type="text/css">
<script>var logged_in = false;
var role = 'student';
var guest_access = true;
var login_required = false;
var js_version = 0.12;
</script>
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div class="hidden-content" style="display:none">\(\newcommand{\bvec}{{\mathbf b}}
\newcommand{\cvec}{{\mathbf c}}
\newcommand{\dvec}{{\mathbf d}}
\newcommand{\evec}{{\mathbf e}}
\newcommand{\fvec}{{\mathbf f}}
\newcommand{\qvec}{{\mathbf q}}
\newcommand{\uvec}{{\mathbf u}}
\newcommand{\vvec}{{\mathbf v}}
\newcommand{\wvec}{{\mathbf w}}
\newcommand{\xvec}{{\mathbf x}}
\newcommand{\yvec}{{\mathbf y}}
\newcommand{\zvec}{{\mathbf z}}
\newcommand{\rvec}{{\mathbf r}}
\newcommand{\zerovec}{{\mathbf 0}}
\newcommand{\real}{{\mathbb R}}
\newcommand{\twovec}[2]{\left[\begin{array}{r}#1 \\ #2
\end{array}\right]}
\newcommand{\ctwovec}[2]{\left[\begin{array}{c}#1 \\ #2
\end{array}\right]}
\newcommand{\threevec}[3]{\left[\begin{array}{r}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\cthreevec}[3]{\left[\begin{array}{c}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\fourvec}[4]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\cfourvec}[4]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\fivevec}[5]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\cfivevec}[5]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\mattwo}[4]{\left[\begin{array}{rr}#1 \amp #2 \\ #3 \amp #4 \\ \end{array}\right]}
\renewcommand{\span}[1]{\text{Span}\{#1\}}
\newcommand{\bcal}{{\cal B}}
\newcommand{\ccal}{{\cal C}}
\newcommand{\scal}{{\cal S}}
\newcommand{\wcal}{{\cal W}}
\newcommand{\ecal}{{\cal E}}
\newcommand{\coords}[2]{\left\{#1\right\}_{#2}}
\newcommand{\gray}[1]{\color{gray}{#1}}
\newcommand{\lgray}[1]{\color{lightgray}{#1}}
\newcommand{\rank}{\text{rank}}
\newcommand{\col}{\text{Col}}
\newcommand{\nul}{\text{Nul}}
\newcommand{\len}[1]{\left|#1\right|}
\newcommand{\bhat}{\widehat{\bvec}}
\newcommand{\xhat}{\widehat{\xvec}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="ula.html"><span class="title">Understanding Linear Algebra</span></a></h1>
<p class="byline">David Austin</p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="sec-eigen-find.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="chap4.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="sec-dynamical.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="sec-eigen-find.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="chap4.html" title="Up">Up</a><a class="next-button button toolbar-item" href="sec-dynamical.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link">
<a href="frontmatter.html" data-scroll="frontmatter"><span class="title">Front Matter</span></a><ul>
<li><a href="dedication-1.html" data-scroll="dedication-1">Dedication</a></li>
<li><a href="colophon-1.html" data-scroll="colophon-1">Colophon</a></li>
<li><a href="preface-1.html" data-scroll="preface-1">Our goals</a></li>
</ul>
</li>
<li class="link">
<a href="chap1.html" data-scroll="chap1"><span class="codenumber">1</span> <span class="title">Systems of Equations</span></a><ul>
<li><a href="sec-expect.html" data-scroll="sec-expect">What can we expect</a></li>
<li><a href="sec-finding-solutions.html" data-scroll="sec-finding-solutions">Finding solutions to systems of linear equations</a></li>
<li><a href="sec-sage-introduction.html" data-scroll="sec-sage-introduction">Computation with Sage</a></li>
<li><a href="sec-pivots.html" data-scroll="sec-pivots">Pivots and their influence on solution spaces</a></li>
</ul>
</li>
<li class="link">
<a href="chap2.html" data-scroll="chap2"><span class="codenumber">2</span> <span class="title">Vectors, Matrices, and Linear Combinations</span></a><ul>
<li><a href="sec-vectors-lin-combs.html" data-scroll="sec-vectors-lin-combs">Vectors and linear combinations</a></li>
<li><a href="sec-matrices-lin-combs.html" data-scroll="sec-matrices-lin-combs">Matrix multiplication and linear combinations</a></li>
<li><a href="sec-span.html" data-scroll="sec-span">The span of a set of vectors</a></li>
<li><a href="sec-linear-dep.html" data-scroll="sec-linear-dep">Linear independence</a></li>
<li><a href="sec-linear-trans.html" data-scroll="sec-linear-trans">Matrix transformations</a></li>
<li><a href="sec-transforms-geom.html" data-scroll="sec-transforms-geom">The geometry of matrix transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap3.html" data-scroll="chap3"><span class="codenumber">3</span> <span class="title">Invertibility, Bases, and Coordinate Systems</span></a><ul>
<li><a href="sec-matrix-inverse.html" data-scroll="sec-matrix-inverse">Invertibility</a></li>
<li><a href="sec-bases.html" data-scroll="sec-bases">Bases and coordinate systems</a></li>
<li><a href="sec-jpeg.html" data-scroll="sec-jpeg">Image compression</a></li>
<li><a href="sec-determinants.html" data-scroll="sec-determinants">Determinants</a></li>
<li><a href="sec-subspaces.html" data-scroll="sec-subspaces">Subspaces of \(\real^p\)</a></li>
</ul>
</li>
<li class="link">
<a href="chap4.html" data-scroll="chap4"><span class="codenumber">4</span> <span class="title">Eigenvalues and eigenvectors</span></a><ul>
<li><a href="sec-eigen-intro.html" data-scroll="sec-eigen-intro">An introduction to eigenvalues and eigenvectors</a></li>
<li><a href="sec-eigen-find.html" data-scroll="sec-eigen-find">Finding eigenvalues and eigenvectors</a></li>
<li><a href="sec-eigen-diag.html" data-scroll="sec-eigen-diag" class="active">Diagonalization, similarity, and powers of a matrix</a></li>
<li><a href="sec-dynamical.html" data-scroll="sec-dynamical">Dynamical systems</a></li>
<li><a href="sec-stochastic.html" data-scroll="sec-stochastic">Markov chains and Google's PageRank algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap5.html" data-scroll="chap5"><span class="codenumber">5</span> <span class="title">Linear algebra and computing</span></a><ul>
<li><a href="sec-gaussian-revisited.html" data-scroll="sec-gaussian-revisited">Gaussian elimination revisited</a></li>
<li><a href="sec-power-method.html" data-scroll="sec-power-method">Finding eigenvectors numerically</a></li>
</ul>
</li>
<li class="link"><a href="backmatter.html" data-scroll="backmatter"><span class="title">Back Matter</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="section" id="sec-eigen-diag"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.3</span> <span class="title">Diagonalization, similarity, and powers of a matrix</span>
</h2>
<a href="sec-eigen-diag.html" class="permalink">¶</a><section class="introduction" id="introduction-21"><p id="p-3914">The first example we considered in this chapter was the matrix \(A=\left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]
\text{,}\) which has eigenvectors \(\vvec_1=\twovec{1}{1}\) and \(\vvec_2 = \twovec{-1}{1}\) and associated eigenvalues \(\lambda_1=3\) and \(\lambda_2=-1\text{.}\)  In <a href="sec-eigen-intro.html#subsec-eigen-use" class="internal" title="Subsection 4.1.2: The usefulness of eigenvalues and eigenvectors">Subsection 4.1.2</a>, we described how \(A\) is, in some sense, equivalent to the diagonal matrix \(D = \left[\begin{array}{rr}
3 \amp 0 \\
0 \amp -1\\
\end{array}\right]
\text{.}\)</p>
<p id="p-3915">This equivalence is summarized by <a data-knowl="./knowl/fig-eigen-diag-A.html" title="Figure 4.3.1">Figure 4.3.1</a>. The diagonal matrix \(D\) has the geometric effect of stretching vectors horizontally by a factor of \(3\) and flipping vectors vertically.  The matrix \(A\) has the geometric effect of stretching vectors by a factor of \(3\) in the direction \(\vvec_1\) and flipping them in the direction of \(\vvec_2\text{.}\)  The geometric effect of \(A\) is the same as that of \(D\) when viewed in a basis of eigenvectors of \(A\text{.}\)</p>
<figure class="figure-like" id="fig-eigen-diag-A"><div class="sidebyside"><div class="sbsrow" style="margin-left:10%;margin-right:10%;"><div class="sbspanel" style="width:100%;justify-content:flex-start;"><img src="images/eigen-intro-A.svg" style="width: 100%; height: auto;" alt=""></div></div></div>
<figcaption><span class="type">Figure</span> <span class="codenumber">4.3.1.</span> The matrix \(A\) has the same geometric effect as the diagonal matrix \(D\) when expressed in the coordinate system defined by the basis of eigenvectors.</figcaption></figure><p id="p-3916">Now that we have developed some algebraic techniques for finding eigenvalues and eigenvectors, we will explore this observation more deeply.  In particular, we will make precise the sense in which \(A\) and \(D\) are equivalent by using the coordinate system defined by the basis of eigenvectors \(\vvec_1\) and \(\vvec_2\text{.}\)</p>
<article class="project-like" id="exploration-16"><h6 class="heading">
<span class="type">Preview Activity</span> <span class="codenumber">4.3.1</span>.</h6>
<p id="p-3917">Let's recall how a vector in \(\real^2\)  can be represented in a coordinate system defined by a basis \(\bcal=\{\vvec_1, \vvec_2\}\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2655">
<p id="p-3918">Suppose that we consider the basis \(\bcal\) defined by</p>
<div class="displaymath">
\begin{equation*}
\vvec_1 = \twovec{1}{1},\qquad
\vvec_2 = \twovec{-1}{0}\text{.}
\end{equation*}
</div>
<p>Find the vector \(\xvec\) whose representation in the coordinate system defined by \(\bcal\) is \(\coords{\xvec}{\bcal} = \twovec{-3}{2}\text{.}\)</p>
</li>
<li id="li-2656"><p id="p-3919">Consider the vector \(\xvec=\twovec{4}{5}\) and find its representation \(\coords{\xvec}{\bcal}\) in the coordinate system defined by \(\bcal\text{.}\)</p></li>
<li id="li-2657"><p id="p-3920">How do we use the matrix \(C_{\bcal} = \left[\begin{array}{rr} \vvec_1 \amp \vvec_2
\end{array}\right]\) to convert a vector's representation \(\coords{\xvec}{\bcal}\) in the coordinate system defined by \(\bcal\) into its standard representation \(\xvec\text{?}\) How do we use this matrix to convert \(\xvec\) into \(\coords{\xvec}{\bcal}\text{?}\)</p></li>
<li id="li-2658"><p id="p-3921">Suppose that we have a matrix \(A\) whose eigenvectors are \(\vvec_1\) and \(\vvec_2\) and associated eigenvalues are \(\lambda_1=4\) and \(\lambda_2
= 2\text{.}\)  Express the vector \(A(-3\vvec_1 +5\vvec_2)\) as a linear combination of \(\vvec_1\) and \(\vvec_2\text{.}\)</p></li>
<li id="li-2659"><p id="p-3922">If \(\coords{\xvec}{\bcal} = \twovec{-3}{5}\text{,}\) find \(\coords{A\xvec}{\bcal}\text{.}\)</p></li>
</ol></article></section><section class="subsection" id="subsection-63"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.1</span> <span class="title">Diagonalization of matrices</span>
</h3>
<p id="p-3929">As we have investigated eigenvalues and eigenvectors of matrices in this chapter, we have frequently asked whether we can find a basis of eigenvectors, as in <a data-knowl="./knowl/question-eigen-basis.html" title="Question 4.1.7">Question 4.1.7</a>.  In fact, <a data-knowl="./knowl/prop-eigen-basis.html" title="Proposition 4.2.3">Proposition 4.2.3</a> tells us that if \(A\) is an \(n\times n\) matrix having distinct and real eigenvalues, then there is a basis for \(\real^n\) consisting of eigenvectors of \(A\text{.}\)  There are, in addition, other conditions on \(A\) that guarantee such a basis, as we will see in subsequent chapters, but for now, suffice it to say that for many matrices, we can find a basis of eigenvectors. We will now see how such a matrix \(A\) is equivalent to a diagonal matrix \(D\text{.}\)</p>
<p id="p-3930">Remember also that we have seen how to use a basis \(\bcal=\{\vvec_1,\vvec_2,\ldots,\vvec_n\}\) of \(\real^n\) to construct a coordinate system for \(\real^n\text{.}\)  In particular, \(\coords{\xvec}{\bcal} = \fourvec{c_1}{c_2}{\vdots}{c_n}\) if \(\xvec = c_1\vvec_1 + c_2\vvec_2 + \ldots + c_n\vvec_n\text{.}\)  We also used matrix multiplication to express this fact:  if \(C_{\bcal} = \left[\begin{array}{rrrr} \vvec_1 \amp \vvec_2 \amp
\ldots \amp \vvec_n \end{array}\right]\text{,}\) then</p>
<div class="displaymath">
\begin{equation*}
\xvec = C_{\bcal}\coords{\xvec}{\bcal}, \qquad
\coords{\xvec}{\bcal} = C_{\bcal}^{-1}\xvec\text{.}
\end{equation*}
</div>
<article class="project-like" id="activity-47"><h6 class="heading">
<span class="type">Activity</span> <span class="codenumber">4.3.2</span>.</h6>
<p id="p-3931">Once again, we will consider the matrices</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right],\qquad
D = \left[\begin{array}{rr}
3 \amp 0 \\
0 \amp -1 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p>The matrix \(A\) has eigenvectors \(\vvec_1=\twovec{1}{1}\) and \(\vvec_2=\twovec{-1}{1}\) and eigenvalues \(\lambda_1=3\) and \(\lambda_2=-1\text{.}\)  We will consider the basis of \(\real^2\) consisting of eigenvectors \(\bcal= \{\vvec_1, \vvec_2\}\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2665"><p id="p-3932">If \(\xvec= 2\vvec_1 - 3\vvec_2\text{,}\) write \(A\xvec\) as a linear combination of \(\vvec_1\) and \(\vvec_2\text{.}\)</p></li>
<li id="li-2666"><p id="p-3933">If \(\coords{\xvec}{\bcal}=\twovec{2}{-3}\text{,}\) find \(\coords{A\xvec}{\bcal}\text{,}\) the representation of \(A\xvec\) in the coordinate system defined by \(\bcal\text{.}\)</p></li>
<li id="li-2667"><p id="p-3934">If \(\coords{\xvec}{\bcal}=\twovec{c_1}{c_2}\text{,}\) find \(\coords{A\xvec}{\bcal}\text{,}\) the representation of \(A\xvec\) in the coordinate system defined by \(\bcal\text{.}\)</p></li>
<li id="li-2668"><p id="p-3935">Explain why \(\coords{A\xvec}{\bcal} =
D\coords{\xvec}{\bcal}\text{.}\)</p></li>
<li id="li-2669">
<p id="p-3936">Explain why \(C_{\bcal}^{-1}A\xvec =
DC_{\bcal}^{-1}\xvec\) for all vectors \(\xvec\) and hence</p>
<div class="displaymath">
\begin{equation*}
C_{\bcal}^{-1}A = DC_{\bcal}^{-1}\text{.}
\end{equation*}
</div>
</li>
<li id="li-2670">
<p id="p-3937">Explain why \(A = C_{\bcal}DC_{\bcal}^{-1}\) and verify this relationship by computing \(C_{\bcal}DC_{\bcal}^{-1}\) in the Sage cell below.</p>
<div class="sagecell-sage" id="sage-107"><script type="text/x-sage"># enter the matrices D and C below	    
D =
C =	    
C*D*C.inverse()
</script></div>
</li>
</ol></article><p id="p-3945">The key to understanding the equivalence of a matrix \(A\) and a diagonal matrix \(D\) is through the coordinate system defined by a basis consisting of eigenvectors of \(A\text{.}\)  We will assume that \(A\) is an \(n\times n\) matrix and that there is a basis \(\bcal=\{\vvec_1,\vvec_2,\ldots,\vvec_n\}\) consisting of eigenvectors of \(A\) with associated eigenvalues \(\lambda_1, \lambda_2,\ldots,\lambda_n\text{.}\)</p>
<p id="p-3946">We know that if</p>
<div class="displaymath">
\begin{equation*}
\xvec = c_1\vvec_1 + c_2\vvec_2 + \ldots + c_n\vvec_n\text{,}
\end{equation*}
</div>
<p>then</p>
<div class="displaymath">
\begin{equation*}
A\xvec = \lambda_1c_1\vvec_1 + \lambda_2c_2\vvec_2 + \ldots +
\lambda_nc_n\vvec_n \text{.}
\end{equation*}
</div>
<p>This fact is conveniently expressed using the coordinate system defined by \(\bcal\text{;}\)  in particular,</p>
<div class="displaymath">
\begin{equation*}
\coords{\xvec}{\bcal} = \fourvec{c_1}{c_2}{\vdots}{c_n},\qquad
\coords{A\xvec}{\bcal} =
\fourvec{\lambda_1c_1}{\lambda_2c_2}{\vdots}{\lambda_nc_n}\text{.}
\end{equation*}
</div>
<p id="p-3947">Forming the diagonal matrix</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{cccc}
\lambda_1 \amp 0 \amp \ldots \amp 0 \\
0 \amp \lambda_2 \amp \ldots \amp 0 \\
\vdots \amp \vdots \amp \ddots \amp 0 \\
0 \amp 0 \amp \ldots \amp \lambda_n \\
\end{array}\right]\text{,}
\end{equation*}
</div>
<p>we see that</p>
<div class="displaymath">
\begin{equation*}
\coords{A\xvec}{\bcal} = D\coords{\xvec}{\bcal}\text{.}
\end{equation*}
</div>
<p id="p-3948">We now use the fact that the matrix \(C_{\bcal} =
\left[\begin{array}{cccc} \vvec_1 \amp \vvec_2 \amp \ldots \amp
\vvec_n \end{array}\right]\) performs the change of coordinates; that is, \(\coords{A\xvec}{\bcal} = C_{\bcal}^{-1}A\xvec\) and \(\coords{\xvec}{\bcal} = C_{\bcal}^{-1}\xvec\text{.}\)  This says that</p>
<div class="displaymath">
\begin{equation*}
C_{\bcal}^{-1}A\xvec = DC_{\bcal}^{-1}\xvec\text{,}
\end{equation*}
</div>
<p>for all vectors \(\xvec\text{,}\) which means that \(C_{\bcal}^{-1}A
= DC_{\bcal}^{-1}\) or</p>
<div class="displaymath">
\begin{equation*}
A = C_{\bcal}DC_{\bcal}^{-1}\text{.}
\end{equation*}
</div>
<p>So that the form of this expression stands out more clearly, it is customary to denote the matrix \(C_{\bcal}\) as \(P\) so that we have \(P = C_{\bcal}\) and hence</p>
<div class="displaymath">
\begin{equation*}
A = PDP^{-1}\text{.}
\end{equation*}
</div>
<article class="definition-like" id="definition-18"><h6 class="heading">
<span class="type">Definition</span> <span class="codenumber">4.3.2</span>.</h6>
<p id="p-3949">We say that the matrix \(A\) is <em class="emphasis">diagonalizable</em> if there is a diagonal matrix \(D\) and invertible matrix \(P\) such that</p>
<div class="displaymath">
\begin{equation*}
A = PDP^{-1}\text{.}
\end{equation*}
</div></article><p id="p-3950">This is the sense in which we mean that \(A\) is equivalent to a diagonal matrix \(D\text{.}\)  The expression \(A=PDP^{-1}\) says that \(A\text{,}\) expressed in the basis defined by the columns of \(P\text{,}\) has the same geometric effect as \(D\text{,}\) expressed in the standard basis \(\evec_1, \evec_2,\ldots,\evec_n\text{.}\)</p>
<p id="p-3951">We have now seen the following proposition.</p>
<article class="theorem-like" id="prop-diagonalizable"><h6 class="heading">
<span class="type">Proposition</span> <span class="codenumber">4.3.3</span>.</h6>
<p id="p-3952">If \(A\) is an \(n\times n\) matrix and there is a basis \(\{\vvec_1,\vvec_2,\ldots,\vvec_n\}\) consisting of eigenvectors of \(A\) having associated eigenvalues \(\lambda_1, \lambda_2, \ldots, \lambda_n\text{,}\) then \(A\) is diagonalizable.  That is, we can write \(A=PDP^{-1}\) where \(D\) is the diagonal matrix whose diagonal entries are the eigenvalues of \(A\)</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{cccc}
\lambda_1 \amp 0 \amp \ldots \amp 0 \\
0 \amp \lambda_2 \amp \ldots \amp 0 \\
\vdots \amp \vdots \amp \ddots \amp 0 \\
0 \amp 0 \amp \ldots \amp \lambda_n \\
\end{array}\right]
\end{equation*}
</div>
<p>and the matrix \(P = \left[\begin{array}{cccc}
\vvec_1 \amp \vvec_2 \amp \ldots \amp \vvec_n
\end{array}\right]
\text{.}\)</p></article><p id="p-3953">In fact, if we only know that \(A = PDP^{-1}\) where \(P =
\left[\begin{array}{cccc} \vvec_1 \amp \vvec_2 \amp \ldots \vvec_n
\end{array}\right]\text{,}\) we can say that the vectors \(\vvec_j\) are eigenvectors of \(A\) and that the associated eigenvalue is the \(j^{th}\) diagonal entry of \(D\text{.}\)</p>
<article class="example-like" id="example-24"><h6 class="heading">
<span class="type">Example</span> <span class="codenumber">4.3.4</span>.</h6>
<p id="p-3954">We will try to find a diagonalization of \(A =
\left[\begin{array}{rr}
-5 \amp 6 \\
-3 \amp 4 \\
\end{array}\right]
\text{.}\)</p>
<p id="p-3955">First, we find the eigenvalues of \(A\) by solving the characteristic equation</p>
<div class="displaymath">
\begin{equation*}
\det(A-\lambda I) = (-5-\lambda)(4-\lambda)+18 =
(-2-\lambda)(1-\lambda) = 0\text{.}
\end{equation*}
</div>
<p>This shows that the eigenvalues of \(A\) are \(\lambda_1 =
-2\) and \(\lambda_2 = 1\text{.}\)</p>
<p id="p-3956">By constructing \(\nul(A-(-2)I)\text{,}\) we find a basis for \(E_{-2}\) consisting of the vector \(\vvec_1 =
\twovec{2}{1}\text{.}\)  Similarly, a basis for \(E_1\) consists of the vector \(\vvec_2 = \twovec{1}{1}\text{.}\)  This shows that we can construct a basis \(\bcal=\{\vvec_1,\vvec_2\}\) of \(\real^2\) consisting of eigenvectors of \(A\text{.}\)</p>
<p id="p-3957">We now form the matrices</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{rr}
-2 \amp 0 \\
0 \amp 1 \\
\end{array}\right],\qquad
P = \left[\begin{array}{cc} \vvec_1 \amp \vvec_2
\end{array}\right] = 
\left[\begin{array}{rr}
2 \amp 1 \\
1 \amp 1 \\
\end{array}\right]
\end{equation*}
</div>
<p>and verify that</p>
<div class="displaymath">
\begin{equation*}
PDP^{-1} =
\left[\begin{array}{rr}
2 \amp 1 \\
1 \amp 1 \\
\end{array}\right]
\left[\begin{array}{rr}
-2 \amp 0 \\
0 \amp 1 \\
\end{array}\right]
\left[\begin{array}{rr}
1 \amp -1 \\
-1 \amp 2 \\
\end{array}\right]
=
\left[\begin{array}{rr}
-5 \amp 6 \\
-3 \amp 4 \\
\end{array}\right] = A\text{.}
\end{equation*}
</div>
<p id="p-3958">There are, of course, many ways to diagonalize \(A\text{.}\) For instance, we could change the order of the eigenvalues and eigenvectors and write</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{rr}
1 \amp 0 \\
0 \amp -2 \\
\end{array}\right],\qquad
P = \left[\begin{array}{cc} \vvec_2 \amp \vvec_1
\end{array}\right] = 
\left[\begin{array}{rr}
1 \amp 2 \\
1 \amp 1 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p id="p-3959">If we choose a different basis for the eigenspaces, we will also find a different matrix \(P\) that diagonalizes \(A\text{.}\)  The point is that there are many ways in which \(A\) can be written in the form \(A=PDP^{-1}\text{.}\)</p></article><article class="example-like" id="example-25"><h6 class="heading">
<span class="type">Example</span> <span class="codenumber">4.3.5</span>.</h6>
<p id="p-3960">We will try to find a diagonalization of \(A =
\left[\begin{array}{rr}
0 \amp 4 \\
-1 \amp 4 \\
\end{array}\right]
\text{.}\)</p>
<p id="p-3961">Once again, we find the eigenvalues by solving the characteristic equation:</p>
<div class="displaymath">
\begin{equation*}
\det(A-\lambda I) = -\lambda(4-\lambda) + 4 = (2-\lambda)^2
= 0\text{.}
\end{equation*}
</div>
<p>In this case, there is a single eigenvalue \(\lambda=2\text{.}\)</p>
<p id="p-3962">We find a basis for the eigenspace \(E_2\) by describing \(\nul(A-2I)\text{:}\)</p>
<div class="displaymath">
\begin{equation*}
A-2I = \left[\begin{array}{rr}
-2 \amp 4 \\
-1 \amp 2 \\
\end{array}\right]
\sim
\left[\begin{array}{rr}
1 \amp -2 \\
0 \amp 0 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p>This shows that the eigenspace \(E_2\) is one-dimensional with \(\vvec_1=\twovec{2}{1}\) forming a basis.</p>
<p id="p-3963">In this case, there is not a basis of \(\real^2\) consisting of eigenvectors of \(A\text{,}\) which tells us that \(A\) is not diagonalizable.</p></article><article class="example-like" id="example-26"><h6 class="heading">
<span class="type">Example</span> <span class="codenumber">4.3.6</span>.</h6>
<p id="p-3964">Suppose we know that \(A=PDP^{-1}\) where</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{rr}
2 \amp 0 \\
0 \amp -2 \\
\end{array}\right],\qquad
P = \left[\begin{array}{cc} \vvec_2 \amp \vvec_1
\end{array}\right] = 
\left[\begin{array}{rr}
1 \amp 1 \\
1 \amp 2 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p id="p-3965">In this case, we know that the columns of \(P\) form eigenvectors of \(A\text{.}\)  For instance, \(\vvec_1 =
\twovec{1}{1}\) is an eigenvector of \(A\) with eigenvalue \(\lambda_1 = 2\text{.}\)  Also, \(\vvec_2 =
\twovec{1}{2}\) is an eigenvector with eigenvalue \(\lambda_2=-2\text{.}\)</p>
<p id="p-3966">We can verify this by computing</p>
<div class="displaymath">
\begin{equation*}
A = PDP^{-1} =
\left[\begin{array}{rr}
6 \amp -4 \\
8 \amp -6 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p>Then, we can compute that \(A\vvec_1 =
\twovec{1}{1}=2\vvec_1\) and \(A\vvec_2 = \twovec{1}{2} =
-2\vvec_2\text{.}\)</p></article><article class="project-like" id="activity-48"><h6 class="heading">
<span class="type">Activity</span> <span class="codenumber">4.3.3</span>.</h6>
<ol id="p-3967" class="lower-alpha">
<li id="li-2677">
<p id="p-3968">Find a diagonalization of \(A\text{,}\) if one exists, when</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rr}
3 \amp -2 \\
6 \amp -5 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
</li>
<li id="li-2678">
<p id="p-3969">Can the diagonal matrix</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rr}
2 \amp 0 \\
0 \amp -5 \\
\end{array}\right]
\end{equation*}
</div>
<p>be diagonalized?  If so, explain how to find the matrices \(P\) and \(D\text{.}\)</p>
</li>
<li id="li-2679">
<p id="p-3970">Find a diagonalization of \(A\text{,}\) if one exists, when</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rrr}
-2 \amp 0 \amp 0 \\
1 \amp -3\amp 0 \\
2 \amp 0 \amp -3 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<div class="sagecell-sage" id="sage-108"><script type="text/x-sage">
</script></div>
</li>
<li id="li-2680">
<p id="p-3971">Find a diagonalization of \(A\text{,}\) if one exists, when</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rrr}
-2 \amp 0 \amp 0 \\
1 \amp -3\amp 0 \\
2 \amp 1 \amp -3 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<div class="sagecell-sage" id="sage-109"><script type="text/x-sage">
</script></div>
</li>
<li id="li-2681">
<p id="p-3972">Suppose that \(A=PDP^{-1}\) where</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{rr}
3 \amp 0 \\
0 \amp -1 \\
\end{array}\right],\qquad
P = \left[\begin{array}{cc} \vvec_2 \amp \vvec_1
\end{array}\right] = 
\left[\begin{array}{rr}
2 \amp 2 \\
1 \amp -1 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<ol class="lower-roman">
<li id="li-2682"><p id="p-3973">Explain why \(A\) is invertible.</p></li>
<li id="li-2683"><p id="p-3974">Find a diagonalization of \(A^{-1}\text{.}\)</p></li>
<li id="li-2684"><p id="p-3975">Find a diagonalization of \(A^3\text{.}\)</p></li>
</ol>
</li>
</ol></article></section><section class="subsection" id="subsection-64"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.2</span> <span class="title">Powers of a diagonalizable matrix</span>
</h3>
<p id="p-3985">In several earlier examples, we have been interested in computing powers of a given matrix.  For instance, in <a data-knowl="./knowl/activity-eigen-intro.html" title="Activity 4.1.3">Activity 4.1.3</a>, we are given the matrix \(A = \left[\begin{array}{rr}
0.8 \amp 0.6 \\
0.2 \amp 0.4 \\
\end{array}\right]\) and an initial vector \(\xvec_0=\twovec{1000}{0}\text{,}\) and we wanted to compute</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
\xvec_1 \amp {}={} A\xvec_0 \\
\xvec_2 \amp {}={} A\xvec_1 = A^2\xvec_0 \\
\xvec_3 \amp {}={} A\xvec_2 = A^3\xvec_0\text{.} \\
\end{aligned}
\end{equation*}
</div>
<p>More generally, we would like to find \(\xvec_k=A^k\xvec_0\) and determine what happens as \(k\) becomes very large.  If a matrix \(A\) is diagonalizable, writing \(A=PDP^{-1}\) can help us understand powers of \(A\) easily.</p>
<article class="project-like" id="activity-49"><h6 class="heading">
<span class="type">Activity</span> <span class="codenumber">4.3.4</span>.</h6>
<ol id="p-3986" class="lower-alpha">
<li id="li-2693">
<p id="p-3987">Let's begin with the diagonal matrix</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{rr}
2 \amp 0 \\
0 \amp -1 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p>Find the powers \(D^2\text{,}\) \(D^3\text{,}\) and \(D^4\text{.}\)  What is \(D^k\) for a general value of \(k\text{?}\)</p>
</li>
<li id="li-2694"><p id="p-3988">Suppose that \(A\) is a matrix with eigenvector \(\vvec\) and associated eigenvalue \(\lambda\text{;}\)  that is, \(A\vvec = \lambda\vvec\text{.}\)  By considering \(A^2\vvec\text{,}\) explain why \(\vvec\) is also an eigenvector of \(A\) with eigenvalue \(\lambda^2\text{.}\)</p></li>
<li id="li-2695">
<p id="p-3989">Suppose that \(A= PDP^{-1}\) where</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{rr}
2 \amp 0 \\
0 \amp -1 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p>Remembering that the columns of \(P\) are eigenvectors of \(A\text{,}\) explain why \(A^2\) is diagonalizable and find a diagonalization of it.</p>
</li>
<li id="li-2696">
<p id="p-3990">Give another explanation of the diagonalizability of \(A^2\) by writing</p>
<div class="displaymath">
\begin{equation*}
A^2 = (PDP^{-1})(PDP^{-1}) = PD(P^{-1}P)DP^{-1}\text{.}
\end{equation*}
</div>
</li>
<li id="li-2697"><p id="p-3991">In the same way, find a diagonalization of \(A^3\text{,}\) \(A^4\text{,}\) and \(A^k\text{.}\)</p></li>
<li id="li-2698"><p id="p-3992">Suppose that \(A\) is a diagonalizable \(2\times2\) matrix with eigenvalues \(\lambda_1 =
0.5\) and \(\lambda_2=0.1\text{.}\)  What happens to \(A^k\) as \(k\) becomes very large?</p></li>
</ol></article><p id="p-4000">We begin by noting that the eigenvectors of a matrix \(A\) are also eigenvectors of the powers of \(A\text{.}\)  For instance, if \(A\vvec = \lambda\vvec\text{,}\) then</p>
<div class="displaymath">
\begin{equation*}
A^2\vvec = A(A\vvec) = A(\lambda\vvec) = \lambda A\vvec =
\lambda^2\vvec\text{.}
\end{equation*}
</div>
<p>In this way, we see that \(\vvec\) is an eigenvector of \(A^2\) with eigenvalue \(\lambda^2\text{.}\)  Furthermore, for any \(k\text{,}\) \(\vvec\) is an eigenvector of \(A^k\) with eigenvalue \(\lambda^k\text{.}\)</p>
<p id="p-4001">Now if \(A\) is diagonalizable, we can write \(A=PDP^{-1}\) where the columns of \(P\) are eigenvectors of \(A\) and the diagonal entries of \(D\) are the eigenvalues.  If \(D = \left[\begin{array}{rr}
\lambda_1 \amp 0 \\
0 \amp \lambda_2 \\
\end{array}\right]
\text{,}\) then</p>
<div class="displaymath">
\begin{equation*}
A^2 = P\left[\begin{array}{rr}
\lambda_1^2 \amp 0 \\
0 \amp \lambda_2^2 \\
\end{array}\right]
P^{-1}
=
PD^2P^{-1}\text{.}
\end{equation*}
</div>
<p>We have the same matrix \(P\) in this expression since the eigenvectors of \(A^2\) are also the eigenvectors of \(A\text{.}\)</p>
<p id="p-4002">Another way to see this is to note that</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
A^2 \amp {}={} (PDP^{-1})(PDP^{-1}) \\
\amp {}={} PD(P^{-1}P)DP^{-1} \\
\amp {}={} PDIDP^{-1} \\
\amp {}={} PDDP^{-1} \\
\amp {}={} PD^2P^{-1}\text{.}
\end{aligned}
\end{equation*}
</div>
<p>Similarly, any power of \(A\) is diagaonalizable;  in particular, \(A^k = PD^kP^{-1}\text{.}\)</p>
<p id="p-4003">In the next section, we will see some important uses of our ability to deal with powers in this way. Until then, consider the case where \(D = \left[\begin{array}{rr}
0.5 \amp 0 \\
0 \amp 0.1 \\
\end{array}\right]\) so that \(D^k = \left[\begin{array}{rr}
0.5^k \amp 0 \\
0 \amp 0.1^k \\
\end{array}\right]
\text{.}\)  As \(k\) becomes very large, the diagonal entries become increasingly close to zero.  This means that \(D^k\) becomes increasingly close to the zero matrix \(\left[\begin{array}{rr}
0 \amp 0 \\
0 \amp 0 \\
\end{array}\right]\) as does \(A^k = PD^kP^{-1}\text{.}\)  In other words, no matter what vector \(\xvec_0\) we begin with, the vectors \(A^k\xvec_0\) becomes increasingly close to \(\zerovec\text{.}\)</p></section><section class="subsection" id="subsection-65"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.3</span> <span class="title">Similarity and complex eigenvalues</span>
</h3>
<p id="p-4004">We have been interested in diagonalizing a matrix \(A\) because doing so relates a matrix \(A\) to a simpler diagonal matrix \(D\text{.}\)  If we write \(A=PDP^{-1}\text{,}\) we see that multiplying a vector by \(A\) in the coordinates defined by the columns of \(P\) is the same as multiplying by \(D\) in standard coordinates.  Under this change of coordinates, \(A\) and \(D\) have the same effect on vectors.</p>
<p id="p-4005">More generally, if we have two matrices \(A\) and \(B\) such that \(A=PBP^{-1}\text{,}\) we may regard multiplication by \(A\) and \(B\) as having the same effect on vectors under the change of coordinates defined by the columns of \(P\text{.}\) That is, if \(\bcal\) is the basis formed by the columns of \(P\text{,}\) then \(\coords{A\xvec}{\bcal} =
B\coords{\xvec}{\bcal}\text{.}\) This leads to the following definition.</p>
<article class="definition-like" id="definition-19"><h6 class="heading">
<span class="type">Definition</span> <span class="codenumber">4.3.7</span>.</h6>
<p id="p-4006">We say that \(A\) is <em class="emphasis">similar</em> to \(B\) if there is an invertible matrix \(P\) such that \(A = PBP^{-1}\text{.}\)</p></article><p id="p-4007">Notice that a matrix is diagonalizable if and only if it is similar to a diagonal matrix.  We have, however, seen several examples of a matrix \(A\) that is not diagonalizable. In this case, it is natural to ask if there is some simpler matrix that is similar to \(A\text{.}\)</p>
<article class="example-like" id="example-eigen-complex"><h6 class="heading">
<span class="type">Example</span> <span class="codenumber">4.3.8</span>.</h6>
<p id="p-4008">Let's consider the matrix \(A = \left[\begin{array}{rr}
-2 \amp 2  \\
-5 \amp 4 \\
\end{array}\right]\) whose characteristic equation is</p>
<div class="displaymath">
\begin{equation*}
\det(A-\lambda I) = (-2-\lambda)(4-\lambda)+10
= 2 - 2\lambda + \lambda^2 = 0\text{.}
\end{equation*}
</div>
<p>Applying the quadratic formula to find the eigenvalues, we obtain</p>
<div class="displaymath">
\begin{equation*}
\lambda = \frac{2\pm\sqrt{(-2)^2-4\cdot1\cdot2}}{2}=1\pm i\text{.}
\end{equation*}
</div>
<p>Here we see that the matrix \(A\) has two complex eigenvalues and is therefore not diagonalizable.</p></article><p id="p-4009">In case a matrix \(A\) has complex eigenvalues, we will find a simpler matrix \(C\) that is similar to \(A\text{.}\)  In particular, if \(A\) has an eigenvalue \(\lambda = a+bi\text{,}\) then \(A\) is similar to \(C=\left[\begin{array}{rr}
a \amp -b \\
b \amp a \\
\end{array}\right]
\text{.}\)</p>
<div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:54.0816326530612%;justify-content:flex-start;">
<p id="p-4010">The next activity shows that \(C\) has a simple geometric effect on \(\real^2\text{.}\)  First, however, we will rewrite \(C\) in polar coordinates, as shown in the figure.  We form the point \((a,b)\text{,}\) which defines \(r\text{,}\) the distance from the origin, and \(\theta\text{,}\) the angle formed with the positive horizontal axis.  We then have</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
a \amp {}={} r\cos\theta \\
b \amp {}={} r\sin\theta\text{.} \\
\end{aligned}
\end{equation*}
</div>
<p>Notice that \(r=\sqrt{a^2+b^2}\text{.}\)</p>
</div>
<div class="sbspanel" style="width:43.8775510204082%;justify-content:flex-start;"><img src="images/eigen-polar.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div>
<article class="project-like" id="activity-50"><h6 class="heading">
<span class="type">Activity</span> <span class="codenumber">4.3.5</span>.</h6>
<ol id="p-4011" class="lower-alpha">
<li id="li-2705">
<p id="p-4012">We will rewrite \(C\) in terms of \(r\) and \(\theta\text{.}\)  Explain why</p>
<div class="displaymath">
\begin{equation*}
\left[\begin{array}{rr}
a \amp -b \\
b \amp a \\
\end{array}\right]
= 
\left[\begin{array}{rr}
r\cos\theta \amp -r\sin\theta \\
r\sin\theta \amp r\cos\theta \\
\end{array}\right]
=
\left[\begin{array}{rr}
r \amp 0 \\
0 \amp r \\
\end{array}\right]
\left[\begin{array}{rr}
\cos\theta \amp -\sin\theta \\
\sin\theta \amp \cos\theta \\
\end{array}\right]\text{.}
\end{equation*}
</div>
</li>
<li id="li-2706"><p id="p-4013">Explain why \(C\) has the geometric effect of rotating vectors by \(\theta\) and stretching them by a factor of \(r\text{.}\)</p></li>
<li id="li-2707">
<p id="p-4014">Let's now consider the matrix \(A\) from <a data-knowl="./knowl/example-eigen-complex.html" title="Example 4.3.8">Example 4.3.8</a>:</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rr}
-2 \amp 2  \\
-5 \amp 4 \\
\end{array}\right]
\end{equation*}
</div>
<p>whose eigenvalues are \(\lambda_1 = 1+i\) and \(\lambda_2 =
1-i\text{.}\)  We will choose to focus on one of the eigenvalues \(\lambda_1 = a+bi= 1+i. \)</p>
<p id="p-4015">Form the matrix \(C\) using these values of \(a\) and \(b\text{.}\)  Then rewrite the point \((a,b)\) in polar coordinates by identifying the values of \(r\) and \(\theta\text{.}\)  Explain the geometric effect of multiplying vectors of \(C\text{.}\)</p>
</li>
<li id="li-2708">
<p id="p-4016">Suppose that \(P=\left[\begin{array}{rr}
1 \amp 1 \\
2 \amp 1 \\
\end{array}\right]
\text{.}\)  Verify that \(A = PCP^{-1}\text{.}\)</p>
<div class="sagecell-sage" id="sage-110"><script type="text/x-sage">C = 
P = 
P*C*P.inverse()
</script></div>
</li>
<li id="li-2709"><p id="p-4017">Explain why \(A^k = PC^kP^{-1}\text{.}\)</p></li>
<li id="li-2710"><p id="p-4018">We formed the matrix \(C\) by choosing the eigenvalue \(\lambda_1=1+i\text{.}\)  Suppose we had instead chosen \(\lambda_2 = 1-i\text{.}\)  Form the matrix \(C'\) and use polar coordinates to describe the geometric effect of \(C\text{.}\)</p></li>
<li id="li-2711"><p id="p-4019">Using the matrix \(P' = \left[\begin{array}{rr}
1 \amp -1 \\
2 \amp -1 \\
\end{array}\right]
\text{,}\) show that \(A = P'C'P'^{-1}\text{.}\)</p></li>
</ol></article><p id="p-4027">If the \(2\times2\) matrix \(A\) has a complex eigenvalue \(\lambda = a + bi\text{,}\) this activity demonstrates the fact that \(A\) is similar to the matrix \(C = \left[\begin{array}{rr}
a \amp -b \\
b \amp a \\
\end{array}\right]
\text{.}\)  When we consider the matrix \(A = \left[\begin{array}{rr}
-2 \amp 2  \\
-5 \amp 4 \\
\end{array}\right]
\text{,}\) we find the complex eigenvalue \(\lambda=1+i\text{,}\) which leads to the matrix</p>
<div class="displaymath">
\begin{equation*}
C = \left[\begin{array}{rr}
1 \amp -1 \\
1 \amp 1 \\
\end{array}\right]
=
\left[\begin{array}{rr}
\sqrt{2} \amp 0 \\
0 \amp \sqrt{2} \\
\end{array}\right]
\left[\begin{array}{rr}
\cos(45^\circ) \amp -\sin(45^\circ) \\
\sin(45^\circ) \amp \cos(45^\circ) \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:54.0816326530612%;justify-content:flex-start;"><p id="p-4028">The matrix has the geometric effect of rotating vectors by \(45^\circ\) and stretching them by a factor of \(\sqrt{2}\text{,}\) as shown in the figure.</p></div>
<div class="sbspanel" style="width:43.8775510204082%;justify-content:flex-start;"><img src="images/eigen-complex-action.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div>
<p id="p-4029">As we saw in the activity, our original matrix \(A\) is similar to \(C\text{.}\)  That is, we saw that there is a matrix \(P\) such that \(A=PCP^{-1}\text{.}\) This means that, when expressed in the coordinates defined by the columns of \(P\text{,}\) multiplying a vector by \(A\) is equivalent to multiplying by \(C\text{;}\)  that is, if \(\bcal\) is the basis formed by the columns of \(A\text{,}\) then \(\coords{A\xvec}{\bcal} =
C\coords{\xvec}{\bcal}\text{.}\)</p>
<p id="p-4030">Had we chosen the other eigenvalue \(\lambda_2 = 1-i\text{,}\) we would have formed the matrix</p>
<div class="displaymath">
\begin{equation*}
C' = \left[\begin{array}{rr}
1 \amp 1 \\
-1 \amp 1 \\
\end{array}\right]
=
\left[\begin{array}{rr}
\sqrt{2} \amp 0 \\
0 \amp \sqrt{2} \\
\end{array}\right]
\left[\begin{array}{rr}
\cos(-45^\circ) \amp -\sin(-45^\circ) \\
\sin(-45^\circ) \amp \cos(-45^\circ) \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p>In other words, this matrix \(C'\) rotates vectors by \(-45^\circ\) and stretches them by a factor of \(\sqrt{2}\text{.}\)  The original matrix \(A\) is also similar to \(C'\text{.}\)</p>
<p id="p-4031">Depending on which complex eigenvalue we choose, we find a matrix \(C\) that performs either a counterclockwise or a clockwise rotation.  In our future uses, we will focus on \(r\text{,}\) the streching factor, and not be concerned about the direction of the rotation.</p></section><section class="subsection" id="subsection-66"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.4</span> <span class="title">Summary</span>
</h3>
<p id="p-4032">The ideas in this section demonstrate how the eigenvalues and eigenvectors of a matrix \(A\) can provide us with a new coordinate system in which multiplying by \(A\) reduces to a simpler operation.</p>
<ul class="disc">
<li id="li-2718"><p id="p-4033">We said that \(A\) is diagonalizable if we can write \(A = PDP^{-1}\) where \(D\) is a diagonal matrix.  The columns of \(P\) consist of eigenvectors of \(A\) and the diagonal entries of \(D\) are the associated eigenvalues.</p></li>
<li id="li-2719"><p id="p-4034">An \(n\times n\) matrix \(A\) is diagonalizable if and only if there is a basis of \(\real^n\) consisting of eigenvectors of \(A\text{.}\)</p></li>
<li id="li-2720"><p id="p-4035">We said that \(A\) and \(B\) are similar if there is an invertible matrix \(P\) such that \(A=PBP^{-1}\text{.}\) In this case, \(A^k = PB^kP^{-1}\text{.}\)</p></li>
<li id="li-2721"><p id="p-4036">If \(A\) is a \(2\times2\) matrix with complex eigenvalue \(\lambda = a+bi\text{,}\) then \(A\) is similar to \(C = \left[\begin{array}{rr}
a \amp -b \\
b \amp a \\
\end{array} \right]
\text{.}\)  Writing the point \((a,b)\) in polar coordinates \(r\) and \(\theta\text{,}\) we see that \(C\) rotates vectors through an angle \(\theta\) and stretches them by a factor of \(r=\sqrt{a^2+b^2}\text{.}\)</p></li>
</ul></section><section class="exercises" id="exercises-17"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">4.3.5</span> <span class="title">Exercises</span>
</h3>
<article class="exercise-like" id="exercise-142"><h6 class="heading"><span class="codenumber">1.</span></h6>
<p id="p-4037">Determine whether the following matrices are diagonalizable.  If so, find matrices \(D\) and \(P\) such that \(A=PDP^{-1}\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2722"><p id="p-4038">\(A = \left[\begin{array}{rr}
-2 \amp -2 \\
-2 \amp 1 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2723"><p id="p-4039">\(A = \left[\begin{array}{rr}
-1 \amp 1 \\
-1 \amp -3 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2724"><p id="p-4040">\(A = \left[\begin{array}{rr}
3 \amp -4 \\
2 \amp -1 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2725"><p id="p-4041">\(A = \left[\begin{array}{rrr}
1 \amp 0 \amp 0 \\
2 \amp -2 \amp 0 \\
0 \amp 1 \amp 4 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2726"><p id="p-4042">\(A = \left[\begin{array}{rrr}
1 \amp 2 \amp 2 \\
2 \amp 1 \amp 2 \\
2 \amp 2 \amp 1 \\
\end{array}\right]
\text{.}\)</p></li>
</ol></article><article class="exercise-like" id="exercise-143"><h6 class="heading"><span class="codenumber">2.</span></h6>
<p id="p-4055">Determine whether the following matrices have complex eigenvalues.  If so, find the matrix \(C\) such that \(A =
PCP^{-1}\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2737"><p id="p-4056">\(A = \left[\begin{array}{rr}
-2 \amp -2 \\
-2 \amp 1 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2738"><p id="p-4057">\(A = \left[\begin{array}{rr}
-1 \amp 1 \\
-1 \amp -3 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2739"><p id="p-4058">\(A = \left[\begin{array}{rr}
3 \amp -4 \\
2 \amp -1 \\
\end{array}\right]
\text{.}\)</p></li>
</ol></article><article class="exercise-like" id="exercise-144"><h6 class="heading"><span class="codenumber">3.</span></h6>
<p id="p-4067">Determine whether the following statements are true or false and provide a justification for your response.</p>
<ol class="lower-alpha">
<li id="li-2746"><p id="p-4068">If \(A\) is invertible, then \(A\) is diagonalizable.</p></li>
<li id="li-2747"><p id="p-4069">If \(A\) and \(B\) are similar and \(A\) is invertible, then \(B\) is also invertible.</p></li>
<li id="li-2748"><p id="p-4070">If \(A\) is a diagonalizable \(n\times n\) matrix, then there is a basis of \(\real^n\) consisting of eigenvectors of \(A\text{.}\)</p></li>
<li id="li-2749"><p id="p-4071">If \(A\) is diagonalizable, then \(A^{10}\) is also diagonalizable.</p></li>
<li id="li-2750"><p id="p-4072">If \(A\) is diagonalizable, then \(A\) is invertible.</p></li>
</ol></article><article class="exercise-like" id="exercise-145"><h6 class="heading"><span class="codenumber">4.</span></h6>
<p id="p-4085">Provide a justification for your response to the following questions.</p>
<ol class="lower-alpha">
<li id="li-2761"><p id="p-4086">If \(A\) is a \(3\times3\) matrix having eigenvalues \(\lambda = 2, 3, -4\text{,}\) can you guarantee that \(A\) is diagonalizable?</p></li>
<li id="li-2762"><p id="p-4087">If \(A\) is a \(2\times 2\) matrix with a complex eigenvalue, can you guarantee that \(A\) is diagonalizable?</p></li>
<li id="li-2763"><p id="p-4088">If \(A\) is similar to the matrix \(B = \left[\begin{array}{rrr}
-5 \amp 0 \amp 0 \\
0 \amp -5 \amp 0 \\
0 \amp 0 \amp 3 \\
\end{array}\right]
\text{,}\) is \(A\) diagonalizable?</p></li>
<li id="li-2764"><p id="p-4089">What matrices are similar to the identity matrix?</p></li>
<li id="li-2765"><p id="p-4090">If \(A\) is a diagonalizable \(2\times2\) matrix with a single eigenvalue \(\lambda = 4\text{,}\) what is \(A\text{?}\)</p></li>
</ol></article><article class="exercise-like" id="exercise-146"><h6 class="heading"><span class="codenumber">5.</span></h6>
<p id="p-4103">Describe geometric effect that the following matrices have on \(\real^2\text{:}\)</p>
<ol class="lower-alpha">
<li id="li-2776"><p id="p-4104">\(A = \left[\begin{array}{rr}
2 \amp 0 \\
0 \amp 2 \\
\end{array}\right]\)</p></li>
<li id="li-2777"><p id="p-4105">\(A = \left[\begin{array}{rr}
4 \amp 2 \\
0 \amp 4 \\
\end{array}\right]\)</p></li>
<li id="li-2778"><p id="p-4106">\(A = \left[\begin{array}{rr}
3 \amp -6 \\
6 \amp 3 \\
\end{array}\right]\)</p></li>
<li id="li-2779"><p id="p-4107">\(A = \left[\begin{array}{rr}
4 \amp 0 \\
0 \amp -2 \\
\end{array}\right]\)</p></li>
<li id="li-2780"><p id="p-4108">\(A = \left[\begin{array}{rr}
1 \amp 3 \\
3 \amp 1 \\
\end{array}\right]\)</p></li>
</ol></article><article class="exercise-like" id="exercise-147"><h6 class="heading"><span class="codenumber">6.</span></h6>
<p id="p-4121">We say that \(A\) is similar to \(B\) if there is a matrix \(P\) such that \(A = PBP^{-1}\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2791"><p id="p-4122">If \(A\) is similar to \(B\text{,}\) explain why \(B\) is similar to \(A\text{.}\)</p></li>
<li id="li-2792"><p id="p-4123">If \(A\) is similar to \(B\) and \(B\) is similar to \(C\text{,}\) explain why \(A\) is similar to \(C\text{.}\)</p></li>
<li id="li-2793"><p id="p-4124">If \(A\) is similar to \(B\) and \(B\) is diagonalizable, explain why \(A\) is diagonalizable.</p></li>
<li id="li-2794"><p id="p-4125">If \(A\) and \(B\) are similar, explain why \(A\) and \(B\) have the same characteristic polynomial;  that is, explain why \(\det(A-\lambda I) =
\det(B-\lambda I)\text{.}\)</p></li>
<li id="li-2795"><p id="p-4126">If \(A\) and \(B\) are similar, explain why \(A\) and \(B\) have the same eigenvalues.</p></li>
</ol></article><article class="exercise-like" id="exercise-148"><h6 class="heading"><span class="codenumber">7.</span></h6>
<p id="p-4139">Suppose that \(A = PDP^{-1}\) where</p>
<div class="displaymath">
\begin{equation*}
D = \left[\begin{array}{rr}
1 \amp 0 \\
0 \amp 0 \\
\end{array}\right],\qquad
P = \left[\begin{array}{rr}
1 \amp -2 \\
2 \amp 1 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-2806"><p id="p-4140">Explain the geometric effect that \(D\) has on vectors in \(\real^2\text{.}\)</p></li>
<li id="li-2807"><p id="p-4141">Explain the geometric effect that \(A\) has on vectors in \(\real^2\text{.}\)</p></li>
<li id="li-2808"><p id="p-4142">What can you say about \(A^2\) and other powers of \(A\text{?}\)</p></li>
<li id="li-2809"><p id="p-4143">Is \(A\) invertible?</p></li>
</ol></article><article class="exercise-like" id="exercise-149"><h6 class="heading"><span class="codenumber">8.</span></h6>
<p id="p-4154">When \(A\) is a \(2\times2\) matrix with a complex eigenvalue \(\lambda = a+bi\text{,}\) we have said that there is a matrix \(P\) such that \(A=PCP^{-1}\) where \(C=\left[\begin{array}{rr}
a \amp -b \\
b \amp a \\
\end{array}\right]
\text{.}\)  In this exercise, we will learn how to find the matrix \(P\text{.}\)  As an example, we will consider the matrix \(A = \left[\begin{array}{rr}
2 \amp 2 \\
-1 \amp 4 \\
\end{array}\right]
\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2818"><p id="p-4155">Show that the eigenvalues of \(A\) are complex.</p></li>
<li id="li-2819"><p id="p-4156">Choose one of the complex eigenvalues \(\lambda=a+bi\) and construct the usual matrix \(C\text{.}\)</p></li>
<li id="li-2820"><p id="p-4157">Using the same eigenvalue, we will find an eigenvector \(\vvec\) where the entries of \(\vvec\) are complex numbers.  As always, we will describe \(\nul(A-\lambda I)\) by constructing the matrix \(A-\lambda I\) and finding its reduced row echelon form.  In doing so, we will necessarily need to use complex arithmetic.</p></li>
<li id="li-2821"><p id="p-4158">We have now found a complex eigenvector \(\vvec\text{.}\) Write \(\vvec = \vvec_1 - i \vvec_2\) to identify vectors \(\vvec_1\) and \(\vvec_2\) having real entries.</p></li>
<li id="li-2822"><p id="p-4159">Construct the matrix \(P = \left[\begin{array}{rr}
\vvec_1 \amp \vvec_2
\end{array}\right]\) and verify that \(A=PCP^{-1}\text{.}\)</p></li>
</ol></article><article class="exercise-like" id="exercise-150"><h6 class="heading"><span class="codenumber">9.</span></h6>
<p id="p-4172">For each of the following matrices, sketch the vector \(\xvec = \twovec{1}{0}\) and powers \(A^k\xvec\) for \(k=1,2,3,4\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2833"><div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><p id="p-4173">\(A = \left[\begin{array}{rr}
0 \amp -1.4 \\
1.4 \amp 0 \\
\end{array}\right]
\text{.}\)</p></div>
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><img src="images/empty.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div></li>
<li id="li-2834"><div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><p id="p-4174">\(A = \left[\begin{array}{rr}
0 \amp -0.8 \\
0.8 \amp 0 \\
\end{array}\right]
\text{.}\)</p></div>
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><img src="images/empty.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div></li>
<li id="li-2835"><div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><p id="p-4175">\(A = \left[\begin{array}{rr}
0 \amp -1 \\
1 \amp 0 \\
\end{array}\right]
\text{.}\)</p></div>
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><img src="images/empty.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div></li>
<li id="li-2836">
<p id="p-4176">Consider a matrix of the form \(C=\left[\begin{array}{rr}
a \amp -b \\
b \amp a \\
\end{array}\right]\) with \(r=\sqrt{a^2+b^2}\text{.}\)  What happens when \(k\) becomes very large when</p>
<ol class="lower-roman">
<li id="li-2837"><p id="p-4177">\(r \lt 1\text{.}\)</p></li>
<li id="li-2838"><p id="p-4178">\(r = 1\text{.}\)</p></li>
<li id="li-2839"><p id="p-4179">\(r \gt 1\text{.}\)</p></li>
</ol>
</li>
</ol></article><article class="exercise-like" id="exercise-151"><h6 class="heading"><span class="codenumber">10.</span></h6>
<p id="p-4196">For each of the following matrices and vectors, sketch the vector \(\xvec\) along with \(A^k\xvec\) for \(k=1,2,3,4\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2854"><div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><div class="displaymath" id="p-4197">
\begin{equation*}
\begin{aligned}
A \amp {}={} \left[\begin{array}{rr}
1.4 \amp 0 \\
0 \amp 0.7 \\
\end{array}\right] \\
\\
\xvec \amp {}={} \twovec{1}{2}\text{.}
\end{aligned}\text{.}
\end{equation*}
</div></div>
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><img src="images/empty.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div></li>
<li id="li-2855"><div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><div class="displaymath" id="p-4198">
\begin{equation*}
\begin{aligned}
A \amp {}={} \left[\begin{array}{rr}
0.6 \amp 0 \\
0 \amp 0.9 \\
\end{array}\right] \\ \\
\xvec \amp {}={} \twovec{4}{3}\text{.}
\end{aligned}
\end{equation*}
</div></div>
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><img src="images/empty.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div></li>
<li id="li-2856"><div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><div class="displaymath" id="p-4199">
\begin{equation*}
\begin{aligned}
A \amp {}={} \left[\begin{array}{rr}
1.2 \amp 0 \\
0 \amp 1.4 \\
\end{array}\right] \\ \\
\xvec\amp{}={}\twovec{2}{1}\text{.}
\end{aligned}
\end{equation*}
</div></div>
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><img src="images/empty.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div></li>
<li id="li-2857"><div class="sidebyside"><div class="sbsrow" style="margin-left:1%;margin-right:1%;">
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;">
<div class="displaymath" id="p-4200">
\begin{equation*}
\begin{aligned}
A \amp {}={} \left[\begin{array}{rr}
0.95 \amp 0.25 \\
0.25 \amp 0.95 \\
\end{array}\right] \\ \\
\xvec\amp{}={}\twovec{3}{0}\text{.}
\end{aligned}
\end{equation*}
</div>
<p>Find the eigenvalues and eigenvectors of \(A\) to create your sketch.</p>
</div>
<div class="sbspanel" style="width:48.9795918367347%;justify-content:flex-start;"><img src="images/empty.svg" style="width: 100%; height: auto;" alt=""></div>
</div></div></li>
<li id="li-2858"><p id="p-4201">If \(A\) is a \(2\times2\) matrix with eigenvalues \(\lambda_1=0.7\) and \(\lambda_2=0.5\) and \(\xvec\) is any vector, what happens to \(A^k\xvec\) when \(k\) becomes very large?</p></li>
</ol></article></section></section></div></main>
</div>
<div class="login-link"><span id="loginlogout" class="login">login</span></div>
<script src="https://pretextbook.org/js/0.12/login.js"></script>
</body>
</html>
