<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2019-12-26T11:11:44-05:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<h6 class="heading"><span class="type">Paragraph</span></h6>
<p>This experiment gives some insight into the choice of \(\alpha\text{.}\)  The smaller \(\alpha\) is, the faster the Markov chain converges.  This is important; since the matrix \(G'\) that Google works with is so large, we would like to minimize the number of terms in the Markov chain that we need to compute.  On the other hand, as we lower \(\alpha\text{,}\) the matrix \(G' = \alpha G + (1-\alpha)H_n\) begins to resemble \(H_n\) more and \(G\) less.  The value \(\alpha=0.85\) is chosen so that the matrix \(G'\) sufficiently resembles \(G\) while having the Markov chain converge in a reasonable amount of steps.</p>
<span class="incontext"><a href="sec-stochastic.html#p-4798">in-context</a></span>
</body>
</html>
