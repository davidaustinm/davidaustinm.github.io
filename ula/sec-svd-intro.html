<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-08-08T13:56:29-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Singular Value Decompositions</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Understanding Linear Algebra">
<meta property="book:author" content=" David Austin ">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script>// Make *any* pre with class 'sagecell-sage' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-sage',
                       linked: true,
                       languages: ['sage'],
                       evalButtonText: 'Evaluate (Sage)'});
</script><script async="" src="https://cse.google.com/cse.js?cx=015103900096539427448:ngwuia10qci"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\avec}{{\mathbf a}}
\newcommand{\bvec}{{\mathbf b}}
\newcommand{\cvec}{{\mathbf c}}
\newcommand{\dvec}{{\mathbf d}}
\newcommand{\dtil}{\widetilde{\mathbf d}}
\newcommand{\evec}{{\mathbf e}}
\newcommand{\fvec}{{\mathbf f}}
\newcommand{\nvec}{{\mathbf n}}
\newcommand{\pvec}{{\mathbf p}}
\newcommand{\qvec}{{\mathbf q}}
\newcommand{\svec}{{\mathbf s}}
\newcommand{\tvec}{{\mathbf t}}
\newcommand{\uvec}{{\mathbf u}}
\newcommand{\vvec}{{\mathbf v}}
\newcommand{\wvec}{{\mathbf w}}
\newcommand{\xvec}{{\mathbf x}}
\newcommand{\yvec}{{\mathbf y}}
\newcommand{\zvec}{{\mathbf z}}
\newcommand{\rvec}{{\mathbf r}}
\newcommand{\mvec}{{\mathbf m}}
\newcommand{\zerovec}{{\mathbf 0}}
\newcommand{\onevec}{{\mathbf 1}}
\newcommand{\real}{{\mathbb R}}
\newcommand{\twovec}[2]{\left[\begin{array}{r}#1 \\ #2
\end{array}\right]}
\newcommand{\ctwovec}[2]{\left[\begin{array}{c}#1 \\ #2
\end{array}\right]}
\newcommand{\threevec}[3]{\left[\begin{array}{r}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\cthreevec}[3]{\left[\begin{array}{c}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\fourvec}[4]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\cfourvec}[4]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\fivevec}[5]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\cfivevec}[5]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\mattwo}[4]{\left[\begin{array}{rr}#1 \amp #2 \\ #3 \amp #4 \\ \end{array}\right]}
\newcommand{\laspan}[1]{\text{Span}\{#1\}}
\newcommand{\bcal}{{\cal B}}
\newcommand{\ccal}{{\cal C}}
\newcommand{\scal}{{\cal S}}
\newcommand{\wcal}{{\cal W}}
\newcommand{\ecal}{{\cal E}}
\newcommand{\coords}[2]{\left\{#1\right\}_{#2}}
\newcommand{\gray}[1]{\color{gray}{#1}}
\newcommand{\lgray}[1]{\color{lightgray}{#1}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\row}{\text{Row}}
\newcommand{\col}{\text{Col}}
\renewcommand{\row}{\text{Row}}
\newcommand{\nul}{\text{Nul}}
\newcommand{\var}{\text{Var}}
\newcommand{\corr}{\text{corr}}
\newcommand{\len}[1]{\left|#1\right|}
\newcommand{\bbar}{\overline{\bvec}}
\newcommand{\bhat}{\widehat{\bvec}}
\newcommand{\bperp}{\bvec^\perp}
\newcommand{\xhat}{\widehat{\xvec}}
\newcommand{\vhat}{\widehat{\vvec}}
\newcommand{\uhat}{\widehat{\uvec}}
\newcommand{\what}{\widehat{\wvec}}
\newcommand{\Sighat}{\widehat{\Sigma}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="ula.html"><span class="title">Understanding Linear Algebra</span></a></h1>
<p class="byline">David Austin</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="sec-pca.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="chap7.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="sec-svd-uses.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="sec-pca.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="chap7.html" title="Up">Up</a><a class="next-button button toolbar-item" href="sec-svd-uses.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter" class="internal"><span class="title">Front Matter</span></a><ul>
<li><a href="dedication-1.html" data-scroll="dedication-1" class="internal">Dedication</a></li>
<li><a href="colophon-1.html" data-scroll="colophon-1" class="internal">Colophon</a></li>
<li><a href="preface-1.html" data-scroll="preface-1" class="internal">Our goals</a></li>
</ul>
</li>
<li class="link">
<a href="chap1.html" data-scroll="chap1" class="internal"><span class="codenumber">1</span> <span class="title">Systems of equations</span></a><ul>
<li><a href="sec-expect.html" data-scroll="sec-expect" class="internal">What can we expect</a></li>
<li><a href="sec-finding-solutions.html" data-scroll="sec-finding-solutions" class="internal">Finding solutions to linear systems</a></li>
<li><a href="sec-sage-introduction.html" data-scroll="sec-sage-introduction" class="internal">Computation with Sage</a></li>
<li><a href="sec-pivots.html" data-scroll="sec-pivots" class="internal">Pivots and their influence on solution spaces</a></li>
</ul>
</li>
<li class="link">
<a href="chap2.html" data-scroll="chap2" class="internal"><span class="codenumber">2</span> <span class="title">Vectors, matrices, and linear combinations</span></a><ul>
<li><a href="sec-vectors-lin-combs.html" data-scroll="sec-vectors-lin-combs" class="internal">Vectors and linear combinations</a></li>
<li><a href="sec-matrices-lin-combs.html" data-scroll="sec-matrices-lin-combs" class="internal">Matrix multiplication and linear combinations</a></li>
<li><a href="sec-span.html" data-scroll="sec-span" class="internal">The span of a set of vectors</a></li>
<li><a href="sec-linear-dep.html" data-scroll="sec-linear-dep" class="internal">Linear independence</a></li>
<li><a href="sec-linear-trans.html" data-scroll="sec-linear-trans" class="internal">Matrix transformations</a></li>
<li><a href="sec-transforms-geom.html" data-scroll="sec-transforms-geom" class="internal">The geometry of matrix transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap3.html" data-scroll="chap3" class="internal"><span class="codenumber">3</span> <span class="title">Invertibility, bases, and coordinate systems</span></a><ul>
<li><a href="sec-matrix-inverse.html" data-scroll="sec-matrix-inverse" class="internal">Invertibility</a></li>
<li><a href="sec-bases.html" data-scroll="sec-bases" class="internal">Bases and coordinate systems</a></li>
<li><a href="sec-jpeg.html" data-scroll="sec-jpeg" class="internal">Image compression</a></li>
<li><a href="sec-determinants.html" data-scroll="sec-determinants" class="internal">Determinants</a></li>
<li><a href="sec-subspaces.html" data-scroll="sec-subspaces" class="internal">Subspaces</a></li>
</ul>
</li>
<li class="link">
<a href="chap4.html" data-scroll="chap4" class="internal"><span class="codenumber">4</span> <span class="title">Eigenvalues and eigenvectors</span></a><ul>
<li><a href="sec-eigen-intro.html" data-scroll="sec-eigen-intro" class="internal">An introduction to eigenvalues and eigenvectors</a></li>
<li><a href="sec-eigen-find.html" data-scroll="sec-eigen-find" class="internal">Finding eigenvalues and eigenvectors</a></li>
<li><a href="sec-eigen-diag.html" data-scroll="sec-eigen-diag" class="internal">Diagonalization, similarity, and powers of a matrix</a></li>
<li><a href="sec-dynamical.html" data-scroll="sec-dynamical" class="internal">Dynamical systems</a></li>
<li><a href="sec-stochastic.html" data-scroll="sec-stochastic" class="internal">Markov chains and Google's PageRank algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap5.html" data-scroll="chap5" class="internal"><span class="codenumber">5</span> <span class="title">Linear algebra and computing</span></a><ul>
<li><a href="sec-gaussian-revisited.html" data-scroll="sec-gaussian-revisited" class="internal">Gaussian elimination revisited</a></li>
<li><a href="sec-power-method.html" data-scroll="sec-power-method" class="internal">Finding eigenvectors numerically</a></li>
</ul>
</li>
<li class="link">
<a href="chap6.html" data-scroll="chap6" class="internal"><span class="codenumber">6</span> <span class="title">Orthogonality and Least Squares</span></a><ul>
<li><a href="sec-dot-product.html" data-scroll="sec-dot-product" class="internal">The dot product</a></li>
<li><a href="sec-transpose.html" data-scroll="sec-transpose" class="internal">Orthogonal complements and the matrix transpose</a></li>
<li><a href="sec-orthogonal-bases.html" data-scroll="sec-orthogonal-bases" class="internal">Orthogonal bases and projections</a></li>
<li><a href="sec-gram-schmidt.html" data-scroll="sec-gram-schmidt" class="internal">Finding orthogonal bases</a></li>
<li><a href="sec-least-squares.html" data-scroll="sec-least-squares" class="internal">Orthogonal least squares</a></li>
</ul>
</li>
<li class="link">
<a href="chap7.html" data-scroll="chap7" class="internal"><span class="codenumber">7</span> <span class="title">The Spectral Theorem and singular value decompositions</span></a><ul>
<li><a href="sec-symmetric-matrices.html" data-scroll="sec-symmetric-matrices" class="internal">Symmetric matrices and variance</a></li>
<li><a href="sec-quadratic-forms.html" data-scroll="sec-quadratic-forms" class="internal">Quadratic forms</a></li>
<li><a href="sec-pca.html" data-scroll="sec-pca" class="internal">Principal Component Analysis</a></li>
<li><a href="sec-svd-intro.html" data-scroll="sec-svd-intro" class="active">Singular Value Decompositions</a></li>
<li><a href="sec-svd-uses.html" data-scroll="sec-svd-uses" class="internal">Using Singular Value Decompositions</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter.html" data-scroll="backmatter" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link"><a href="app-sage-reference.html" data-scroll="app-sage-reference" class="internal"><span class="codenumber">A</span> <span class="title">Sage Reference</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1" class="internal"><span class="title">Index</span></a></li>
<li class="link"><a href="colophon-2.html" data-scroll="colophon-2" class="internal"><span class="title">Colophon</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="section" id="sec-svd-intro"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">7.4</span> <span class="title">Singular Value Decompositions</span>
</h2>
<section class="introduction" id="introduction-37"><p id="p-7818">The Spectral Theorem has motivated the past few sections.  In particular, we applied the fact that symmetric matrices can be orthogonally diagonalized to simplify quadratic forms, which enabled us to use principal component analysis to reduce the dimension of a dataset.</p>
<p id="p-7819">But what can we do with matrices that are not symmetric or even square?  For instance, the following matrices are not diagonalizable, much less orthogonally so:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{bmatrix}
2 \amp 1 \\
0 \amp 2
\end{bmatrix},
\hspace{24pt}
\begin{bmatrix}
1 \amp 1 \amp 0 \\
-1 \amp 0 \amp 1
\end{bmatrix}.
\end{equation*}
</div>
<p class="continuation">In this section, we will develop a description of matrices called the <em class="emphasis">singular value decomposition</em> that is, in many ways, analogous to an orthogonal diagonalization. For example, we have seen that any symmetric matrix can be written in the form <span class="process-math">\(QDQ^T\)</span> where <span class="process-math">\(Q\)</span> is an orthogonal matrix and <span class="process-math">\(D\)</span> is diagonal.  A singular value decomposition will have the form <span class="process-math">\(U\Sigma V^T\)</span> where <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> are orthogonal and <span class="process-math">\(\Sigma\)</span> is diagonal.  Most notably, we will see that <em class="emphasis">every</em> matrix has a singular value decomposition whether it's symmetric or not.</p>
<article class="exploration project-like" id="exploration-29"><h3 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">7.4.1</span><span class="period">.</span>
</h3>
<p id="p-7820">Let's review orthogonal diagonalizations and quadratic forms as our understanding of singular value decompositions will rely on them.</p>
<ol class="lower-alpha">
<li id="li-5439"><p id="p-7821">Suppose that <span class="process-math">\(A\)</span> is any matrix.  Explain why the matrix <span class="process-math">\(G = A^TA\)</span> is symmetric.</p></li>
<li id="li-5440"><p id="p-7822">Suppose that <span class="process-math">\(A = \begin{bmatrix}
1 \amp 2 \\
-2 \amp -1 \\
\end{bmatrix}\text{.}\)</span>  Find the matrix <span class="process-math">\(G=A^TA\)</span> and write out the quadratic form <span class="process-math">\(q_G\left(\twovec{x_1}{x_2}\right)\)</span> as a function of <span class="process-math">\(x_1\)</span> and <span class="process-math">\(x_2\text{.}\)</span></p></li>
<li id="li-5441"><p id="p-7823">What is the maximum value of <span class="process-math">\(q_G(\xvec)\)</span> and in which direction does it occur? <pre class="ptx-sagecell sagecell-sage" id="sage-237"><script type="text/x-sage">
</script></pre></p></li>
<li id="li-5442"><p id="p-7824">What is the minimum value of <span class="process-math">\(q_G(\xvec)\)</span> and in which direction does it occur?</p></li>
<li id="li-5443"><p id="p-7825">What is the geometric relationship between the directions in which the maximum and minimum values occur?</p></li>
</ol></article></section><section class="subsection" id="subsection-109"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">7.4.1</span> <span class="title">Finding singular value decompositions</span>
</h3>
<p id="p-7832">We will begin by explaining what a singular value decomposition is and how we can find one for a given matrix <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-7833">Recall how the orthogonal diagonalization of a symmetric matrix is formed: if <span class="process-math">\(A\)</span> is symmetric, we write <span class="process-math">\(A = QDQ^T\)</span> where the diagonal entries of <span class="process-math">\(D\)</span> are the eigenvalues of <span class="process-math">\(A\)</span> and the columns of <span class="process-math">\(Q\)</span> are the associated eigenvectors.  Moreover, the eigenvalues are related to the maximum and minimum values of the associated quadratic form <span class="process-math">\(q_A(\uvec)\)</span> among all unit vectors.</p>
<p id="p-7834">A general matrix, particularly a matrix that is not square, may not have eigenvalues and eigenvectors, but we can discover analogous features, called <em class="emphasis">singular values</em> and <em class="emphasis">singular vectors</em>, by studying a function somewhat similar to a quadratic form.  More specifically, any matrix <span class="process-math">\(A\)</span> defines a function</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
l_A(\xvec) = |A\xvec|,
\end{equation*}
</div>
<p class="continuation">which measures the length of <span class="process-math">\(A\xvec\text{.}\)</span> For example, the diagonal matrix <span class="process-math">\(D=\begin{bmatrix}
3 \amp 0 \\
0 \amp -2 \\
\end{bmatrix}\)</span> gives the function <span class="process-math">\(l_D(\xvec) = \sqrt{9x_1^2 + 4x_2^2}\text{.}\)</span> The presence of the square root means that this function is not a quadratic form.  We can, however, define the singular values and vectors by looking for the maximum and minimum of this function <span class="process-math">\(l_A(\uvec)\)</span> among all unit vectors <span class="process-math">\(\uvec\text{.}\)</span></p>
<p id="p-7835">While <span class="process-math">\(l_A(\xvec)\)</span> is not itself a quadratic form, it becomes one if we square it:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\left(l_A(\xvec)\right)^2 = |A\xvec|^2 = (A\xvec)\cdot(A\xvec)
= \xvec\cdot(A^TA\xvec)=q_{A^TA}(\xvec)\text{.}
\end{equation*}
</div>
<p class="continuation"> We call <span class="process-math">\(G=A^TA\text{,}\)</span> the <em class="emphasis">Gram matrix</em> associated to <span class="process-math">\(A\)</span> and note that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
l_A(\xvec) = \sqrt{q_G(\xvec)}\text{.}
\end{equation*}
</div>
<p class="continuation">This is important in the next activity, which introduces singular values and singular vectors.</p>
<article class="activity project-like" id="activity-101"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.4.2</span><span class="period">.</span>
</h4>
<p id="p-7836">The following interactive figure will help us explore singular values and vectors geometrically before we begin a more algebraic approach.</p>
<figure class="figure figure-like" id="js-svd"><div style="width:600px;"><p id="p-7838">You may choose a <span class="process-math">\(2\times2\)</span> matrix <span class="process-math">\(A=\begin{bmatrix}
a \amp b \\
c \amp d \\
\end{bmatrix}\)</span> using the four sliders at the top of the diagram.  On the left, you may vary the red unit vector <span class="process-math">\(\xvec\)</span> by clicking in the head of the vector.</p></div>
<iframe id="interactive-svd" width="600" height="400" src="interactive-svd-if.html"></iframe><figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.4.1<span class="period">.</span></span><span class="space"> </span>Singular values, right singular vectors and left singular vectors</figcaption></figure><p id="p-7839">Select the matrix <span class="process-math">\(A=\begin{bmatrix}
1 \amp 2 \\
-2 \amp - 1 \\
\end{bmatrix}\text{.}\)</span> As we vary the vector <span class="process-math">\(\xvec\text{,}\)</span> we see the vector <span class="process-math">\(A\xvec\)</span> on the right in gray while the height of the blue bar to the right tells us <span class="process-math">\(l_A(\xvec) =
|A\xvec|\text{.}\)</span></p>
<ol id="p-7840" class="lower-alpha">
<li id="li-5449">
<p id="p-7841">The first <em class="emphasis">singular value</em> <span class="process-math">\(\sigma_1\)</span> is the maximum value of <span class="process-math">\(l_A(\xvec)\)</span> and an associated <em class="emphasis">right singular vector</em> <span class="process-math">\(\vvec_1\)</span> is a unit vector describing a direction in which this maximum occurs.</p>
<p id="p-7842">Use the diagram to find the first singular value <span class="process-math">\(\sigma_1\)</span> and an associated right singular vector <span class="process-math">\(\vvec_1\text{.}\)</span></p>
</li>
<li id="li-5450">
<p id="p-7843">The second singular value <span class="process-math">\(\sigma_2\)</span> is the minimum value of <span class="process-math">\(l_A(\xvec)\)</span> and an associated right singular vector <span class="process-math">\(\vvec_2\)</span> is a unit vector describing a direction in which this minimum occurs.</p>
<p id="p-7844">Use the diagram to find the second singular value <span class="process-math">\(\sigma_2\)</span> and an associated right singular vector <span class="process-math">\(\vvec_2\text{.}\)</span></p>
</li>
<li id="li-5451"><p id="p-7845">Here's how we can find the right singular values and vectors without using the diagram.  Remember that <span class="process-math">\(l_A(\xvec) = \sqrt{q_G(\xvec)}\)</span> where <span class="process-math">\(G=A^TA\)</span> is the Gram matrix associated to <span class="process-math">\(A\text{.}\)</span>  Since <span class="process-math">\(G\)</span> is symmetric, it is orthogonally diagonalizable.  Find <span class="process-math">\(G\)</span> and an orthogonal diagonalization of it. <pre class="ptx-sagecell sagecell-sage" id="sage-238"><script type="text/x-sage">
</script></pre> What is the maximum value of the quadratic form <span class="process-math">\(q_G(\xvec)\)</span> among all unit vectors and in which direction does it occur?  What is the minimum value of <span class="process-math">\(q_G(\xvec)\)</span> and in which direction does it occur?</p></li>
<li id="li-5452"><p id="p-7846">Because <span class="process-math">\(l_A(\xvec) = \sqrt{q_G(\xvec)}\text{,}\)</span> the first singular value <span class="process-math">\(\sigma_1\)</span> will be the square root of the maximum value of <span class="process-math">\(q_G(\xvec)\)</span> and <span class="process-math">\(\sigma_2\)</span> the square root of the minimum. Verify that the singular values that you found from the diagram are the square roots of the maximum and minimum values of <span class="process-math">\(q_G(\xvec)\text{.}\)</span></p></li>
<li id="li-5453"><p id="p-7847">Verify that the right singular vectors <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> that you found from the diagram are the directions in which the maximum and minimum values occur.</p></li>
<li id="li-5454"><p id="p-7848">Finally, we introduce the <em class="emphasis">left singular vectors</em> <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> by requiring that <span class="process-math">\(A\vvec_1 = \sigma_1\uvec_1\)</span> and <span class="process-math">\(A\vvec_2=\sigma_2\uvec_2\text{.}\)</span>  Find the two left singular vectors. <pre class="ptx-sagecell sagecell-sage" id="sage-239"><script type="text/x-sage">
</script></pre></p></li>
<li id="li-5455">
<p id="p-7849">Form the matrices</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U = \begin{bmatrix}\uvec_1 \amp \uvec_2
\end{bmatrix}, \hspace{24pt}
\Sigma = \begin{bmatrix}
\sigma_1 \amp 0 \\
0 \amp \sigma_2 \\
\end{bmatrix}, \hspace{24pt}
V = \begin{bmatrix}\vvec_1 \amp \vvec_2
\end{bmatrix}
\end{equation*}
</div>
<p class="continuation">and explain why <span class="process-math">\(AV = U\Sigma\text{.}\)</span></p>
</li>
<li id="li-5456"><p id="p-7850">Finally, explain why <span class="process-math">\(A=U\Sigma V^T\)</span> and verify that this relationship holds for this specific example.</p></li>
</ol></article><p id="p-7869">As this activity shows, the singular values of <span class="process-math">\(A\)</span> are the maximum and minimum values of <span class="process-math">\(l_A(\xvec)=|A\xvec|\)</span> among all unit vectors and the right singular vectors <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> are the directions in which they occur.  The key to finding the singular values and vectors is to utilize the Gram matrix <span class="process-math">\(G\)</span> and its associated quadratic form <span class="process-math">\(q_G(\xvec)\text{.}\)</span>  We will illustrate with some more examples.</p>
<article class="example example-like" id="example-76"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.4.2</span><span class="period">.</span>
</h4>
<p id="p-7870">We will find a singular value decomposition of the matrix <span class="process-math">\(A=\begin{bmatrix}
1 \amp 2 \\
-1 \amp 2
\end{bmatrix}
\text{.}\)</span>  Notice that this matrix is not symmetric so it cannot be orthogonally diagonalized.</p>
<p id="p-7871">We begin by constructing the Gram matrix <span class="process-math">\(G = A^TA =
\begin{bmatrix} 
2 \amp 0 \\
0 \amp 8 \\
\end{bmatrix}\text{.}\)</span>  Since <span class="process-math">\(G\)</span> is symmetric, it can be orthogonally diagonalized with</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D = \begin{bmatrix}
8 \amp 0 \\
0 \amp 2 \\
\end{bmatrix},\hspace{24pt}
Q = \begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
<p id="p-7872">We now know that the maximum value of the quadratic form <span class="process-math">\(q_G(\xvec)\)</span> is 8, which occurs in the direction <span class="process-math">\(\twovec01\text{.}\)</span>  Since <span class="process-math">\(l_A(\xvec) =
\sqrt{q_G(\xvec)}\text{,}\)</span> this tells us that the maximum value of <span class="process-math">\(l_A(\xvec)\text{,}\)</span> the first singular value, is <span class="process-math">\(\sigma_1=\sqrt{8}\)</span> and that this occurs in the direction of the first right singular vector <span class="process-math">\(\vvec_1=\twovec01\text{.}\)</span></p>
<p id="p-7873">In the same way, we also know that the second singular value <span class="process-math">\(\sigma_2=\sqrt{2}\)</span> with associated right singular vector <span class="process-math">\(\vvec_2=\twovec10\text{.}\)</span></p>
<p id="p-7874">The first left singular vector <span class="process-math">\(\uvec_1\)</span> is defined by <span class="process-math">\(A\vvec_1 = \twovec22 = \sigma_1\uvec_1\text{.}\)</span>  Because <span class="process-math">\(\sigma_1 = \sqrt{8}\text{,}\)</span> we have <span class="process-math">\(\uvec_1
= \twovec{1/\sqrt{2}}{1/\sqrt{2}}\text{.}\)</span>  Notice that <span class="process-math">\(\uvec_1\)</span> is a unit vector because <span class="process-math">\(\sigma_1 =
|A\vvec_1|\text{.}\)</span></p>
<p id="p-7875">In the same way, the second left singular vector is defined by <span class="process-math">\(A\vvec_2 = \twovec1{-1} = \sigma_2\uvec_2\text{,}\)</span> which gives us <span class="process-math">\(\uvec_2 = \twovec{1/\sqrt{2}}{-1/\sqrt{2}}\text{.}\)</span></p>
<p id="p-7876">We then construct</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-31">
\begin{align*}
U \amp {}={} \begin{bmatrix}
\uvec_1 \amp \uvec_2 \end{bmatrix} =
\begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2} \\
\end{bmatrix}\\
\Sigma \amp {}={} \begin{bmatrix}
\sigma_1 \amp 0 \\
0 \amp \sigma_2 \\
\end{bmatrix} = 
\begin{bmatrix} 
\sqrt{8} \amp 0 \\
0 \amp \sqrt{2} \\
\end{bmatrix}\\
V \amp {}={} \begin{bmatrix}
\vvec_1 \amp \vvec_2 \end{bmatrix} =
\begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix}
\end{align*}
</div>
<p id="p-7877">We now have <span class="process-math">\(AV=U\Sigma\)</span> because</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
AV = \begin{bmatrix}
A\vvec_1 \amp A\vvec_2
\end{bmatrix}
= \begin{bmatrix}
\sigma_1\uvec_1 \amp \sigma_2\uvec_2
\end{bmatrix}
= \Sigma U\text{.}
\end{equation*}
</div>
<p class="continuation">Because the right singular vectors, the columns of <span class="process-math">\(V\text{,}\)</span> are eigenvectors of the symmetric matrix <span class="process-math">\(G\text{,}\)</span> they form an orthonormal basis, which means that <span class="process-math">\(V\)</span> is orthogonal.  Therefore, we have <span class="process-math">\((AV)V^T = A = U\Sigma
V^T\text{.}\)</span>  This gives the singular value decomposition</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A = \begin{bmatrix}
1 \amp 2 \\
-1 \amp 2 \\
\end{bmatrix} =
\begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2} \\
\end{bmatrix}
\begin{bmatrix}
\sqrt{8} \amp 0 \\
0 \amp \sqrt{2} \\
\end{bmatrix}
\begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix}^T
= U\Sigma V^T\text{.}
\end{equation*}
</div></article><p id="p-7878">To summarize, we find a singular value decomposition of a matrix <span class="process-math">\(A\)</span> in the following way:</p>
<ul class="disc">
<li id="li-5473"><p id="p-7879">Construct the Gram matrix <span class="process-math">\(G=A^TA\)</span> and find an orthogonal diagonalization to obtain eigenvalues <span class="process-math">\(\lambda_i\)</span> and an orthonormal basis of eigenvectors.</p></li>
<li id="li-5474"><p id="p-7880">The singular values of <span class="process-math">\(A\)</span> are the squares roots of eigenvalues <span class="process-math">\(\lambda_i\)</span> of <span class="process-math">\(G\text{;}\)</span> that is, <span class="process-math">\(\sigma_i = \sqrt{\lambda_i}\text{.}\)</span>  By convention, the singular values are listed in decreasing order: <span class="process-math">\(\sigma_1 \geq \sigma_2 \geq \ldots
\text{.}\)</span>  The right singular vectors <span class="process-math">\(\vvec_i\)</span> are the associated eigenvectors of <span class="process-math">\(G\text{.}\)</span></p></li>
<li id="li-5475">
<p id="p-7881">The left singular vectors <span class="process-math">\(\uvec_i\)</span> are found by <span class="process-math">\(A\vvec_i = \sigma_i\uvec_i\text{.}\)</span>  Because <span class="process-math">\(\sigma_i=|A\vvec_i|\text{,}\)</span> we know that <span class="process-math">\(\uvec_i\)</span> will be a unit vector.</p>
<p id="p-7882">In fact, the left singular vectors will also form an orthonormal basis.  To see this, suppose that the associcated singular values are nonzero.  We then have:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-32">
\begin{align*}
\sigma_i\sigma_j(\uvec_i\cdot\uvec_j) \amp {}={}
(\sigma_i\uvec_i)\cdot(\sigma_j\uvec_j) =
(A\vvec_i)\cdot(A\vvec_j)\\
\amp {}={}
\vvec_i\cdot(A^TA\vvec_j) \\
\amp {}={}
\vvec_i\cdot(G\vvec_j) =
\lambda_j\vvec_i\cdot\vvec_j = 0
\end{align*}
</div>
<p class="continuation">since the right singular vectors are orthogonal.</p>
</li>
</ul>
<article class="example example-like" id="example-77"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.4.3</span><span class="period">.</span>
</h4>
<p id="p-7883">Let's find a singular value decomposition for the symmetric matrix <span class="process-math">\(A=\begin{bmatrix}
1 \amp 2 \\
2 \amp 1
\end{bmatrix}\text{.}\)</span> The associated Gram matrix is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
G = A^TA = \begin{bmatrix}
5 \amp 4 \\
4 \amp 5 \\
\end{bmatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">which has an orthogonal diagonalization with</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D = \begin{bmatrix}
9 \amp 0 \\
0 \amp 1 \\
\end{bmatrix},\hspace{24pt}
Q = \begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2} \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
<p class="continuation">This gives singular values and vectors</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-33">
\begin{align*}
\sigma_1 = 3, \hspace{24pt}\amp \vvec_1 =
\twovec{1/\sqrt{2}}{1/\sqrt{2}}, 
\amp \uvec_1 = \twovec{1/\sqrt{2}}{1/\sqrt{2}}\\
\sigma_2 = 1, \hspace{24pt}\amp \vvec_2 =
\twovec{1/\sqrt{2}}{-1/\sqrt{2}}, 
\amp \uvec_2 = \twovec{-1/\sqrt{2}}{1/\sqrt{2}}
\end{align*}
</div>
<p class="continuation">and the singular value decomposition <span class="process-math">\(A=U\Sigma V^T\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U = \begin{bmatrix}
1/\sqrt{2} \amp -1/\sqrt{2} \\
1/\sqrt{2} \amp 1/\sqrt{2}
\end{bmatrix},\hspace{24pt}
\Sigma = \begin{bmatrix}
3 \amp 0 \\
0 \amp 1
\end{bmatrix},\hspace{24pt}
V = \begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2}
\end{bmatrix}.
\end{equation*}
</div>
<p id="p-7884">This example is special because <span class="process-math">\(A\)</span> is symmetric.  With a little thought, it's possible to relate this singular value decomposition to an orthogonal diagonalization of <span class="process-math">\(A\)</span> using the fact that <span class="process-math">\(G=A^TA = A^2\text{.}\)</span></p></article><article class="activity project-like" id="activity-102"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.4.3</span><span class="period">.</span>
</h4>
<p id="p-7885">In this activity, we will construct the singular value decomposition of <span class="process-math">\(A=\begin{bmatrix} 1 \amp 0 \amp -1 \\
1 \amp 1 \amp 1
\end{bmatrix}\text{.}\)</span> Notice that this matrix is not square so there are no eigenvalues and eigenvectors associated to it.</p>
<ol class="lower-alpha">
<li id="li-5476"><p id="p-7886">Construct the Gram matrix <span class="process-math">\(G=A^TA\)</span> and find an orthogonal diagonalization of it. <pre class="ptx-sagecell sagecell-sage" id="sage-240"><script type="text/x-sage">
</script></pre></p></li>
<li id="li-5477"><p id="p-7887">Identify the singular values of <span class="process-math">\(A\)</span> and the right singular vectors <span class="process-math">\(\vvec_1\text{,}\)</span> <span class="process-math">\(\vvec_2\text{,}\)</span> and <span class="process-math">\(\vvec_3\text{.}\)</span>  What is the dimension of these vectors?  How many nonzero singular values are there?</p></li>
<li id="li-5478"><p id="p-7888">Find the left singular vectors <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> using the fact that <span class="process-math">\(A\vvec_i =
\sigma_i\uvec_i\text{.}\)</span> What is the dimension of these vectors? What happens if you try to find a third left singular vector <span class="process-math">\(\uvec_3\)</span> in this way?</p></li>
<li id="li-5479"><p id="p-7889">As before, form the orthogonal matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> from the left and right singular vectors. What are the shapes of <span class="process-math">\(U\)</span> and <span class="process-math">\(V\text{?}\)</span> How do these shapes relate to the number of rows and columns of <span class="process-math">\(A\text{?}\)</span></p></li>
<li id="li-5480">
<p id="p-7890">Now form <span class="process-math">\(\Sigma\)</span> so that it has the same shape as <span class="process-math">\(A\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Sigma = \begin{bmatrix}
\sigma_1 \amp 0 \amp 0 \\
0 \amp \sigma_2 \amp 0
\end{bmatrix}
\end{equation*}
</div>
<p class="continuation">and verify that <span class="process-math">\(A = U\Sigma V^T\text{.}\)</span> <pre class="ptx-sagecell sagecell-sage" id="sage-241"><script type="text/x-sage">
</script></pre></p>
</li>
<li id="li-5481"><p id="p-7891">How can you use this singular value decomposition of <span class="process-math">\(A=U\Sigma V^T\)</span> to easily find a singular value decomposition of <span class="process-math">\(A^T=\begin{bmatrix}
1 \amp 1 \\
0 \amp 1 \\
-1 \amp 1 \\
\end{bmatrix}\text{?}\)</span></p></li>
</ol></article><article class="example example-like" id="example-svd-nonsquare"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.4.4</span><span class="period">.</span>
</h4>
<p id="p-7907">We will find a singular value decomposition of the matrix <span class="process-math">\(A=\begin{bmatrix}
2 \amp -2 \amp 1 \\
-4 \amp -8 \amp -8 \\
\end{bmatrix}\text{.}\)</span></p>
<p id="p-7908">Finding an orthogonal diagonalization of <span class="process-math">\(G=A^TA\)</span> gives</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
D=\begin{bmatrix}
144 \amp 0 \amp 0 \\
0 \amp 9 \amp 0 \\
0 \amp 0 \amp 0 \\
\end{bmatrix},\hspace{24pt}
Q=\begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
2/3 \amp -2/3 \amp 1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">which gives singular values <span class="process-math">\(\sigma_1=\sqrt{144}=12\text{,}\)</span> <span class="process-math">\(\sigma_2 = \sqrt{9}= 3\text{,}\)</span> and <span class="process-math">\(\sigma_3 = 0\text{.}\)</span> The right singular vectors <span class="process-math">\(\vvec_i\)</span> appear as the columns of <span class="process-math">\(Q\)</span> so that <span class="process-math">\(V = Q\text{.}\)</span></p>
<p id="p-7909">We now find</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-35">
\begin{align*}
A\vvec_1 = \twovec{0}{-12} = 12\uvec_1,
\hspace{24pt}
\amp
\uvec_1 = \twovec{0}{-1}\\
A\vvec_2 = \twovec{3}{0} = 3\uvec_1,
\hspace{24pt}
\amp
\uvec_1 = \twovec10\\
A\vvec_3 = \twovec{0}{0}
\end{align*}
</div>
<p class="continuation">Notice that it's not possible to find a third left singular vector since <span class="process-math">\(A\vvec_3=\zerovec\text{.}\)</span> We therefore form the matrices</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U = \begin{bmatrix}
0 \amp 1 \\
-1 \amp 0 \\
\end{bmatrix},\hspace{24pt}
\Sigma = \begin{bmatrix}
12 \amp 0 \amp 0 \\
0 \amp 3 \amp 0 \\
\end{bmatrix},\hspace{24pt}
V=\begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
2/3 \amp -2/3 \amp 1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}\text{,}
\end{equation*}
</div>
<p class="continuation">which gives the singular value decomposition <span class="process-math">\(A=U\Sigma V^T\text{.}\)</span></p>
<p id="p-7910">Notice that <span class="process-math">\(U\)</span> is a <span class="process-math">\(2\times2\)</span> orthogonal matrix because <span class="process-math">\(A\)</span> has two rows, and <span class="process-math">\(V\)</span> is a <span class="process-math">\(3\times3\)</span> orthogonal matrix because <span class="process-math">\(A\)</span> has three columns.</p></article><p id="p-7911">As we'll see in the next section, some additional work may be needed to construct the left singular vectors <span class="process-math">\(\uvec_j\)</span> if more of the singular values are zero, but we won't worry about that now.  For the time being, let's record our work in the following theorem.</p>
<article class="theorem theorem-like" id="theorem-svd"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">7.4.5</span><span class="period">.</span><span class="space"> </span><span class="title">The singular value decomposition.</span>
</h4>An <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A\)</span> may be written as <span class="process-math">\(A=U\Sigma V^T\)</span> where <span class="process-math">\(U\)</span> is an orthogonal <span class="process-math">\(m\times m\)</span> matrix, <span class="process-math">\(V\)</span> is an orthogonal <span class="process-math">\(n\times n\)</span> matrix, and <span class="process-math">\(\Sigma\)</span> is an <span class="process-math">\(m\times
n\)</span> matrix whose entries are zero except for the singular values of <span class="process-math">\(A\)</span> which appear in decreasing order on the diagonal.</article><p id="p-7912">Notice that a singular value decomposition of <span class="process-math">\(A\)</span> gives us a singular value decomposition of <span class="process-math">\(A^T\text{.}\)</span>  More specifically, if <span class="process-math">\(A=U\Sigma V^T\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A^T = (U\Sigma V^T)^T = V\Sigma^T U^T.
\end{equation*}
</div>
<article class="proposition theorem-like" id="prop-svd-transpose"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.4.6</span><span class="period">.</span>
</h4>
<p id="p-7913">If <span class="process-math">\(A=U\Sigma V^T\text{,}\)</span> then <span class="process-math">\(A^T = V\Sigma^T U^T\text{.}\)</span> In other words, <span class="process-math">\(A\)</span> and <span class="process-math">\(A^T\)</span> share the same singular values, and the left singular vectors of <span class="process-math">\(A\)</span> are the right singular vectors of <span class="process-math">\(A^T\)</span> and vice-versa.</p></article><p id="p-7914">As we said earlier, a singular value decomposition should be thought of a generalization of an orthogonal diagonalization. For instance, the Spectral Theorem tells us that a symmetric matrix can be written as <span class="process-math">\(QDQ^T\text{.}\)</span>  Many matrices, however, are not symmetric and so they are not orthogonally diagonalizable.  However, every matrix has a singular value decomposition <span class="process-math">\(U\Sigma V^T\text{.}\)</span>  The price of this generalization is that we usually have two sets of singular vectors that form the orthogonal matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> whereas a symmetric matrix has a single set of eignevectors that form the orthogonal matrix <span class="process-math">\(Q\text{.}\)</span></p></section><section class="subsection" id="subsection-110"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">7.4.2</span> <span class="title">The structure of singular value decompositions</span>
</h3>
<p id="p-7915">Now that we have an understanding of what a singular value decomposition is and how to construct it, let's explore the ways in which a singular value decomposition reveals the underlying structure of the matrix.  As we'll see, the matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> in a singular value decomposition provide convenient bases for some important subspaces, such as the column and null spaces of the matrix.  This observation will provide the key to some of our uses of these decompositions in the next section.</p>
<article class="activity project-like" id="activity-103"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.4.4</span><span class="period">.</span>
</h4>
<p id="p-7916">Let's suppose that a matrix <span class="process-math">\(A\)</span> has a singular value decomposition <span class="process-math">\(A=U\Sigma V^T\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U=\begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix},\hspace{10pt}
\Sigma = \begin{bmatrix}
20 \amp 0 \amp 0 \\
0 \amp 5 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix},\hspace{10pt}
V=\begin{bmatrix}
\vvec_1 \amp \vvec_2 \amp \vvec_3
\end{bmatrix}.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5494"><p id="p-7917">What is the shape of <span class="process-math">\(A\text{;}\)</span> that is, how many rows and columns does <span class="process-math">\(A\)</span> have?</p></li>
<li id="li-5495">
<p id="p-7918">Suppose we write a three-dimensional vector <span class="process-math">\(\xvec\)</span> as a linear combination of right singular vectors:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\xvec = c_1\vvec_1 + c_2\vvec_2 + c_3\vvec_3\text{.}
\end{equation*}
</div>
<p class="continuation">We would like to find an expression for <span class="process-math">\(A\xvec\text{.}\)</span></p>
<p id="p-7919">To begin, <span class="process-math">\(V^T\xvec = \threevec{\vvec_1\cdot\xvec}
{\vvec_2\cdot\xvec}
{\vvec_3\cdot\xvec} = \threevec{c_1}{c_2}{c_3}
\text{.}\)</span></p>
<p id="p-7920">Now <span class="process-math">\(\Sigma V^T \xvec = 
\begin{bmatrix}
20 \amp 0 \amp 0 \\
0 \amp 5 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix}\threevec{c_1}{c_2}{c_3}
= \cfourvec{20c_1}{5c_2}00\text{.}\)</span></p>
<p id="p-7921">And finally, <span class="process-math">\(A\xvec = U\Sigma V^T\xvec =
\begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix}
\cfourvec{20c_1}{5c_2}00 =
20c_1\uvec_1 + 5c_2\uvec_2\text{.}\)</span></p>
<p id="p-7922">To summarize, we have <span class="process-math">\(A\xvec = 20c_1\uvec_1 +
5c_2\uvec_2\text{.}\)</span></p>
<p id="p-7923">What condition on <span class="process-math">\(c_1\text{,}\)</span> <span class="process-math">\(c_2\text{,}\)</span> and <span class="process-math">\(c_3\)</span> must be satisfied if <span class="process-math">\(\xvec\)</span> is a solution to the equation <span class="process-math">\(A\xvec=40\uvec_1 + 20\uvec_2\text{?}\)</span> Is there a unique solution or infinitely many?</p>
</li>
<li id="li-5496"><p id="p-7924">Remembering that <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> are linearly independent, what condition on <span class="process-math">\(c_1\text{,}\)</span> <span class="process-math">\(c_2\text{,}\)</span> and <span class="process-math">\(c_3\)</span> must be satisfied if <span class="process-math">\(A\xvec = \zerovec\text{?}\)</span></p></li>
<li id="li-5497"><p id="p-7925">How do the right singular vectors <span class="process-math">\(\vvec_i\)</span> provide a basis for <span class="process-math">\(\nul(A)\text{,}\)</span> the subspace of solutions to the equation <span class="process-math">\(A\xvec = \zerovec\text{?}\)</span></p></li>
<li id="li-5498">
<p id="p-7926">Remember that <span class="process-math">\(\bvec\)</span> is in <span class="process-math">\(\col(A)\)</span> if the equation <span class="process-math">\(A\xvec = \bvec\)</span> is consistent, which means that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A\xvec = 20c_1\uvec_1 + 5c_2\uvec_2 = \bvec
\end{equation*}
</div>
<p class="continuation">for some coefficients <span class="process-math">\(c_1\)</span> and <span class="process-math">\(c_2\text{.}\)</span>  How do the left singular vectors <span class="process-math">\(\uvec_i\)</span> provide an orthonormal basis for <span class="process-math">\(\col(A)\text{?}\)</span></p>
</li>
<li id="li-5499"><p id="p-7927">Remember that <span class="process-math">\(\rank(A)\)</span> is the dimension of the column space.  What is <span class="process-math">\(\rank(A)\)</span> and how do the number of nonzero singular values determine <span class="process-math">\(\rank(A)\text{?}\)</span></p></li>
</ol></article><p id="p-7942">This activity shows how a singular value decomposition of a matrix encodes important information about its null and column spaces.  More specifically, the left and right singular vectors provide orthonormal bases for <span class="process-math">\(\nul(A)\)</span> and <span class="process-math">\(\col(A)\text{.}\)</span> This is one of the reasons that singular value decompositions are so useful.</p>
<article class="example example-like" id="example-79"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.4.7</span><span class="period">.</span>
</h4>
<p id="p-7943">Suppose we have a singular value decomposition <span class="process-math">\(A=U\Sigma
V^T\)</span> where <span class="process-math">\(\Sigma = \begin{bmatrix}
\sigma_1 \amp 0 \amp 0 \amp 0 \amp 0 \\
0 \amp \sigma_2 \amp 0 \amp 0 \amp 0 \\
0 \amp 0 \amp \sigma_3 \amp 0 \amp 0 \\
0 \amp 0 \amp 0 \amp 0 \amp 0 \\
\end{bmatrix}
\text{.}\)</span>  This means that <span class="process-math">\(A\)</span> has four rows and five columns just as <span class="process-math">\(\Sigma\)</span> does.</p>
<p id="p-7944">As in the activity, if <span class="process-math">\(\xvec = c_1 \vvec_1 + c_2\vvec_2 +
\ldots + c_5\vvec_5\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A\xvec = \sigma_1c_1\uvec_1 + \sigma_2c_2\uvec_2 +
\sigma_3c_3\uvec_3\text{.}
\end{equation*}
</div>
<p id="p-7945">If <span class="process-math">\(\bvec\)</span> is in <span class="process-math">\(\col(A)\text{,}\)</span> then <span class="process-math">\(\bvec\)</span> must have the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\bvec = \sigma_1c_1\uvec_1 + \sigma_2c_2\uvec_2 +
\sigma_3c_3\uvec_3\text{,}
\end{equation*}
</div>
<p class="continuation">which says that <span class="process-math">\(\bvec\)</span> is a linear combination of <span class="process-math">\(\uvec_1\text{,}\)</span> <span class="process-math">\(\uvec_2\text{,}\)</span> and <span class="process-math">\(\uvec_3\text{.}\)</span> These three vectors therefore form a basis for <span class="process-math">\(\col(A)\text{.}\)</span>  In fact, since they are columns in the orthogonal matrix <span class="process-math">\(U\text{,}\)</span> they form an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span></p>
<p id="p-7946">Remembering that <span class="process-math">\(\rank(A)=\dim\col(A)\text{,}\)</span> we see that <span class="process-math">\(\rank(A) = 3\text{,}\)</span> which results from the three nonzero singular values.  In general, the rank <span class="process-math">\(r\)</span> of a matrix <span class="process-math">\(A\)</span> equals the number of nonzero singular values, and <span class="process-math">\(\uvec_1, \uvec_2, \ldots,\uvec_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span></p>
<p id="p-7947">Moreover, if <span class="process-math">\(\xvec = c_1 \vvec_1 + c_2\vvec_2 +
\ldots + c_5\vvec_5\)</span> satisfies <span class="process-math">\(A\xvec = \zerovec\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A\xvec = \sigma_1c_1\uvec_1 + \sigma_2c_2\uvec_2 +
\sigma_3c_3\uvec_3=\zerovec\text{,}
\end{equation*}
</div>
<p class="continuation">which implies that <span class="process-math">\(c_1=0\text{,}\)</span> <span class="process-math">\(c_2=0\text{,}\)</span> and <span class="process-math">\(c_3=0\text{.}\)</span>  Therefore, <span class="process-math">\(\xvec =
c_4\vvec_4+c_5\vvec_5\)</span> so <span class="process-math">\(\vvec_4\)</span> and <span class="process-math">\(\vvec_5\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span></p>
<p id="p-7948">More generally, if <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\times n\)</span> matrix and if <span class="process-math">\(\rank(A) = r\text{,}\)</span> the last <span class="process-math">\(n-r\)</span> right singular vectors form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span></p></article><p id="p-7949">Generally speaking, if the rank of an <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A\)</span> is <span class="process-math">\(r\text{,}\)</span> then there are <span class="process-math">\(r\)</span> nonzero singular values and <span class="process-math">\(\Sigma\)</span> has the form</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{bmatrix}
\sigma_1 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp \sigma_r \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
\vdots \amp \vdots \amp \vdots \amp \ddots \amp \vdots \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
\end{bmatrix},
\end{equation*}
</div>
<p class="continuation">The first <span class="process-math">\(r\)</span> columns of <span class="process-math">\(U\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U = \left[
\underbrace{\uvec_1 ~ \ldots ~ \uvec_r}_{\col(A)} \hspace{3pt}
\uvec_{r+1} ~ \ldots ~ \uvec_m
\right]
\end{equation*}
</div>
<p class="continuation">and the last <span class="process-math">\(n-r\)</span> columns of <span class="process-math">\(V\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = \left[
\vvec_1 ~ \ldots ~ \vvec_r\hspace{3pt}
\underbrace{\vvec_{r+1} ~ \ldots ~ \vvec_n}_{\nul(A)}
\right]
\end{equation*}
</div>
<p id="p-7950">Remember that <a href="" class="xref" data-knowl="./knowl/prop-svd-transpose.html" title="Proposition 7.4.6">Proposition 7.4.6</a> says that <span class="process-math">\(A\)</span> and its transpose <span class="process-math">\(A^T\)</span> share the same singular values.  Since the rank of a matrix equals its number of nonzero singular values, this means that <span class="process-math">\(\rank(A)=\rank(A^T)\text{,}\)</span> a fact that we cited back in <a href="sec-transpose.html" class="internal" title="Section 6.2: Orthogonal complements and the matrix transpose">Section 6.2</a>.</p>
<article class="proposition theorem-like" id="prop-rank-transpose"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.4.8</span><span class="period">.</span>
</h4>
<p id="p-7951">For any matrix <span class="process-math">\(A\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\rank(A) =
\rank(A^T)\text{.}
\end{equation*}
</div></article><p id="p-7952">If we have a singular value decomposition of an <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A=U\Sigma V^T\text{,}\)</span> <a href="" class="xref" data-knowl="./knowl/prop-svd-transpose.html" title="Proposition 7.4.6">Proposition 7.4.6</a> also tells us that the left singular vectors of <span class="process-math">\(A\)</span> are the right singular vectors of <span class="process-math">\(A^T\text{.}\)</span>  Therefore, <span class="process-math">\(U\)</span> is the <span class="process-math">\(m\times m\)</span> matrix whose columns are the right singular vectors of <span class="process-math">\(A^T\text{.}\)</span>  This means that the last <span class="process-math">\(m-r\)</span> vectors form an orthonormal basis for <span class="process-math">\(\nul(A^T)\text{.}\)</span> Therefore, the columns of <span class="process-math">\(U\)</span> provide orthonormal bases for <span class="process-math">\(\col(A)\)</span> and <span class="process-math">\(\nul(A^T)\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-svd-transpose.html">
\begin{equation*}
U = \left[
\underbrace{\uvec_1 ~ \ldots ~ \uvec_r}_{\col(A)} \hspace{3pt}
\underbrace{\uvec_{r+1} ~ \ldots ~ \uvec_m}_{\nul(A^T)}
\right]\text{.}
\end{equation*}
</div>
<p class="continuation">This reflects the familiar fact that <span class="process-math">\(\nul(A^T)\)</span> is the orthogonal complement of <span class="process-math">\(\col(A)\text{.}\)</span></p>
<p id="p-7953"> In the same way, <span class="process-math">\(V\)</span> is the <span class="process-math">\(n\times n\)</span> matrix whose columns are the left singular vectors of <span class="process-math">\(A^T\text{,}\)</span> which means that the first <span class="process-math">\(r\)</span> vectors form an orthonormal basis for <span class="process-math">\(\col(A^T)\text{.}\)</span>  Because the columns of <span class="process-math">\(A^T\)</span> are the rows of <span class="process-math">\(A\text{,}\)</span> this subspace is sometimes called the <em class="emphasis">row space</em> of <span class="process-math">\(A\)</span> and denoted <span class="process-math">\(\row(A)\text{.}\)</span>  While we have yet to have an occasion to use <span class="process-math">\(\row(A)\text{,}\)</span> there are times when it is important to have an orthonormal basis for it, and a singular value decomposition provides just that.  To summarize, the columns of <span class="process-math">\(V\)</span> provide orthonormal bases for <span class="process-math">\(\col(A^T)\)</span> and <span class="process-math">\(\nul(A)\text{:}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
V = \left[
\underbrace{\vvec_1 ~ \ldots ~ \vvec_r}_{\col(A^T)}\hspace{3pt}
\underbrace{\vvec_{r+1} ~ \ldots ~ \vvec_m}_{\nul(A)}
\right]
\end{equation*}
</div>
<p id="p-7954">Considered altogether, the subspaces <span class="process-math">\(\col(A)\text{,}\)</span> <span class="process-math">\(\nul(A)\text{,}\)</span> <span class="process-math">\(\col(A^T)\text{,}\)</span> and <span class="process-math">\(\nul(A^T)\)</span> are called the <em class="emphasis">four fundamental subspaces</em> associated to <span class="process-math">\(A\text{.}\)</span>  In addition to telling us the rank of a matrix, a singular value decomposition gives us orthonormal bases for all four fundamental subspaces.</p>
<article class="theorem theorem-like" id="thm-four-subspaces"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">7.4.9</span><span class="period">.</span>
</h4>
<p id="p-7955">Suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\times n\)</span> matrix having a singular value decomposition <span class="process-math">\(A=U\Sigma V^T\text{.}\)</span>  Then</p>
<ul class="disc">
<li id="li-5512"><p id="p-7956"><span class="process-math">\(r=\rank(A)\)</span> is the number of nonzero singular values.</p></li>
<li id="li-5513"><p id="p-7957">The columns <span class="process-math">\(\uvec_1,\uvec_2,\ldots,\uvec_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span></p></li>
<li id="li-5514"><p id="p-7958">The columns <span class="process-math">\(\uvec_{r+1},\ldots,\uvec_m\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A^T)\text{.}\)</span></p></li>
<li id="li-5515"><p id="p-7959">The columns <span class="process-math">\(\vvec_1,\vvec_2,\ldots,\vvec_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A^T)\text{.}\)</span></p></li>
<li id="li-5516"><p id="p-7960">The columns <span class="process-math">\(\vvec_{r+1},\ldots,\vvec_n\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span></p></li>
</ul></article><p id="p-7961">When we previously outlined a procedure for finding a singular decomposition of an <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> we found the left singular vectors <span class="process-math">\(\uvec_j\)</span> using the expression <span class="process-math">\(A\vvec_j = \sigma_j\uvec_j\text{.}\)</span>  This produces left singular vectors <span class="process-math">\(\uvec_1, \uvec_2,\ldots,\uvec_r\text{,}\)</span> where <span class="process-math">\(r=\rank(A)\text{.}\)</span>  If <span class="process-math">\(r\lt m\text{,}\)</span> however, we still need to find the left singular vectors <span class="process-math">\(\uvec_{r+1},\ldots,\uvec_m\text{.}\)</span>  <a href="" class="xref" data-knowl="./knowl/thm-four-subspaces.html" title="Theorem 7.4.9">Theorem 7.4.9</a> tells us how to do that: because those vectors form an orthonormal basis for <span class="process-math">\(\nul(A^T)\text{,}\)</span> we can find them by solving <span class="process-math">\(A^T\xvec = \zerovec\)</span> to obtain a basis for <span class="process-math">\(\nul(A^T)\)</span> and applying the Gram-Schmidt algorithm.</p>
<p id="p-7962">We won't worry about this issue too much, however, as we will frequently use software to find singular value decompositions for us.</p></section><section class="subsection" id="subsection-111"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">7.4.3</span> <span class="title">Reduced singular value decompositions</span>
</h3>
<p id="p-7963">As we'll see in the next section, there are times when it is helpful to express a singular value decomposition in a slightly different form.</p>
<article class="activity project-like" id="activity-104"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.4.5</span><span class="period">.</span>
</h4>
<p id="p-7964">Suppose we have a singular value decomposition <span class="process-math">\(A =
U\Sigma V^T\)</span> where</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U = \begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix},\hspace{24pt}
\Sigma = \begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0 \\
\end{bmatrix},\hspace{24pt}
V = \begin{bmatrix}
\vvec_1 \amp \vvec_2 \amp \vvec_3 
\end{bmatrix}\text{.}
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5517"><p id="p-7965">What is the shape of <span class="process-math">\(A\text{?}\)</span>  What is <span class="process-math">\(\rank(A)\text{?}\)</span></p></li>
<li id="li-5518"><p id="p-7966">Identify bases for <span class="process-math">\(\col(A)\)</span> and <span class="process-math">\(\col(A^T)\text{.}\)</span></p></li>
<li id="li-5519">
<p id="p-7967">Explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
U\Sigma = \begin{bmatrix}
\uvec_1 \amp \uvec_2
\end{bmatrix}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</li>
<li id="li-5520">
<p id="p-7968">Explain why</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}V^T =
\begin{bmatrix}
18 \amp 0 \\
0 \amp 4 \\
\end{bmatrix}
\begin{bmatrix}
\vvec_1 \amp \vvec_2
\end{bmatrix}^T\text{.}
\end{equation*}
</div>
</li>
<li id="li-5521"><p id="p-7969">If <span class="process-math">\(A = U\Sigma V^T\text{,}\)</span> explain why <span class="process-math">\(A=U_r\Sigma_rV_r^T\)</span> where the columns of <span class="process-math">\(U_r\)</span> are an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span> <span class="process-math">\(\Sigma_r\)</span> is a square, diagonal, invertible matrix, and the columns of <span class="process-math">\(V_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A^T)\text{.}\)</span></p></li>
</ol></article><p id="p-7982">We call this a <em class="emphasis">reduced singular value decomposition</em>.</p>
<article class="proposition theorem-like" id="prop-reduced-svd"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.4.10</span><span class="period">.</span><span class="space"> </span><span class="title">Reduced singular value decomposition.</span>
</h4>
<p id="p-7983">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\times n\)</span> matrix having rank <span class="process-math">\(r\text{,}\)</span> then <span class="process-math">\(A=U_r \Sigma_r V_r^T\)</span> where</p>
<ul class="disc">
<li id="li-5532"><p id="p-7984"><span class="process-math">\(U_r\)</span> is an <span class="process-math">\(m\times r\)</span> matrix whose columns form an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span></p></li>
<li id="li-5533"><p id="p-7985"><span class="process-math">\(\Sigma_r=\begin{bmatrix}
\sigma_1 \amp 0 \amp \ldots \amp 0 \\
0 \amp \sigma_2 \amp \ldots \amp 0 \\
\vdots \amp \vdots \amp \ddots \amp \vdots \\
0 \amp 0 \amp 0 \amp \sigma_r \\
\end{bmatrix}\)</span> is an <span class="process-math">\(r\times r\)</span> diagonal, invertible matrix, and</p></li>
<li id="li-5534"><p id="p-7986"><span class="process-math">\(V_r\)</span> is an <span class="process-math">\(n\times r\)</span> matrix whose columns form an orthonormal basis for <span class="process-math">\(\col(A^T)\text{.}\)</span></p></li>
</ul></article><article class="example example-like" id="example-80"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.4.11</span><span class="period">.</span>
</h4>
<p id="p-7987">In <a href="" class="xref" data-knowl="./knowl/example-svd-nonsquare.html" title="Example 7.4.4">Example 7.4.4</a>, we found the singular value decomposition</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-svd-nonsquare.html">
\begin{equation*}
A=\begin{bmatrix}
2 \amp -2 \amp 1 \\
-4 \amp -8 \amp -8 \\
\end{bmatrix}
= \begin{bmatrix}
0 \amp 1 \\
-1 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
12 \amp 0 \amp 0 \\
0 \amp 3 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
2/3 \amp -2/3 \amp 1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}^T\text{.}
\end{equation*}
</div>
<p class="continuation">Since there are two nonzero singular values, <span class="process-math">\(\rank(A)
=2\)</span> so that the reduced singular value decomposition is</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-svd-nonsquare.html">
\begin{equation*}
A=\begin{bmatrix}
2 \amp -2 \amp 1 \\
-4 \amp -8 \amp -8 \\
\end{bmatrix}
= \begin{bmatrix}
0 \amp 1 \\
-1 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
12 \amp 0  \\
0 \amp 3 \\
\end{bmatrix}
\begin{bmatrix}
1/3 \amp 2/3  \\
2/3 \amp -2/3  \\
2/3 \amp 1/3  \\
\end{bmatrix}^T\text{.}
\end{equation*}
</div></article></section><section class="subsection" id="subsection-112"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">7.4.4</span> <span class="title">Summary</span>
</h3>
<p id="p-7988">This section has explored singular value decompositions, how to find them, and how they organize important information about a matrix.</p>
<ul class="disc">
<li id="li-5535"><p id="p-7989">A singular value decomposition of a matrix <span class="process-math">\(A\)</span> is a factorization where <span class="process-math">\(A=U\Sigma V^T\text{.}\)</span>  The matrix <span class="process-math">\(\Sigma\)</span> has the same shape as <span class="process-math">\(A\text{,}\)</span> and its only nonzero entries are the singular values of <span class="process-math">\(A\text{,}\)</span> which appear in decreasing order on the diagonal.  The matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> are orthogonal and contain the left and right singular vectors, respectively, as their columns.</p></li>
<li id="li-5536"><p id="p-7990">To find a singular value decomposition of a matrix, we construct the Gram matrix <span class="process-math">\(G=A^TA\text{,}\)</span> which is symmetric.  The singular values of <span class="process-math">\(A\)</span> are the square roots of the eigenvalues of <span class="process-math">\(G\text{,}\)</span> and the right singular vectors <span class="process-math">\(\vvec_j\)</span> are the associated eigenvectors of <span class="process-math">\(G\text{.}\)</span>  The left singular vectors <span class="process-math">\(\uvec_j\)</span> are determined from the relationship <span class="process-math">\(A\vvec_j=\sigma_j\uvec_j\text{.}\)</span></p></li>
<li id="li-5537"><p id="p-7991">A singular value decomposition reveals fundamental information about a matrix.  For instance, the number of nonzero singular values is the rank <span class="process-math">\(r\)</span> of the matrix.  The first <span class="process-math">\(r\)</span> left singular vectors form an orthonormal basis for <span class="process-math">\(\col(A)\)</span> with the remaining left singular vectors forming an orthonormal basis of <span class="process-math">\(\nul(A^T)\text{.}\)</span>  The first <span class="process-math">\(r\)</span> right singular vectors form an orthonormal basis for <span class="process-math">\(\col(A^T)\)</span> while the remaining right singular vectors form an orthonormal basis of <span class="process-math">\(\nul(A)\text{.}\)</span></p></li>
<li id="li-5538"><p id="p-7992">If <span class="process-math">\(A\)</span> is a rank <span class="process-math">\(r\)</span> matrix, we can write a reduced singular value decomposition as <span class="process-math">\(A=U_r\Sigma_rV_r^T\)</span> where the columns of <span class="process-math">\(U_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span> the columns of <span class="process-math">\(V_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A^T)\text{,}\)</span> and <span class="process-math">\(\Sigma_r\)</span> is an <span class="process-math">\(r\times
r\)</span> diagonal, invertible matrix.</p></li>
</ul></section><section class="exercises" id="exercises-30"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">7.4.5</span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="ex-7-4-1"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<p id="p-7993">Consider the matrix <span class="process-math">\(A = \begin{bmatrix}
1 \amp 2 \amp 1 \\
0 \amp -1 \amp 2 \\
\end{bmatrix}
\text{.}\)</span> <pre class="ptx-sagecell sagecell-sage" id="sage-242"><script type="text/x-sage">
</script></pre></p>
<ol class="lower-alpha">
<li id="li-5539"><p id="p-7994">Find the Gram matrix <span class="process-math">\(G=A^TA\)</span> and use it to find the singular values and right singular vectors of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-5540"><p id="p-7995">Find the left singular vectors.</p></li>
<li id="li-5541"><p id="p-7996">Form the matrices <span class="process-math">\(U\text{,}\)</span> <span class="process-math">\(\Sigma\text{,}\)</span> and <span class="process-math">\(V\)</span> and verify that <span class="process-math">\(A=U\Sigma V^T\text{.}\)</span></p></li>
<li id="li-5542"><p id="p-7997">What is <span class="process-math">\(\rank(A)\)</span> and what does this say about <span class="process-math">\(\col(A)\text{?}\)</span></p></li>
<li id="li-5543"><p id="p-7998">Determine an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-276"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<p id="p-8013">Find singular value decompositions for the following matrices:</p>
<ol class="lower-alpha">
<li id="li-5554"><p id="p-8014"><span class="process-math">\(\begin{bmatrix} 0 \amp 0 \\ 0 \amp -8
\end{bmatrix}\text{.}\)</span></p></li>
<li id="li-5555"><p id="p-8015"><span class="process-math">\(\begin{bmatrix} 2 \amp 3 \\ 0 \amp 2
\end{bmatrix}\text{.}\)</span></p></li>
<li id="li-5556"><p id="p-8016"><span class="process-math">\(\displaystyle \begin{bmatrix}
4 \amp 0 \amp 0 \\
0 \amp 0 \amp 2
\end{bmatrix}\)</span></p></li>
<li id="li-5557"><p id="p-8017"><span class="process-math">\(\displaystyle \begin{bmatrix}
4 \amp 0 \\
0 \amp 0 \\
0 \amp 2 
\end{bmatrix}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-277"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<p id="p-8028">Consider the matrix <span class="process-math">\(A = \begin{bmatrix}
2 \amp 1 \\
1 \amp 2
\end{bmatrix}
\text{.}\)</span></p>
<ol class="lower-alpha">
<li id="li-5566"><p id="p-8029">Find a singular value decomposition of <span class="process-math">\(A\)</span> and verify that it is also an orthogonal diagonalization of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-5567"><p id="p-8030">If <span class="process-math">\(A\)</span> is a symmetric, positive semidefinite matrix, explain why a singular value decomposition of <span class="process-math">\(A\)</span> is an orthogonal diagonalization of <span class="process-math">\(A\text{.}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-278"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<p id="p-8039">Suppose that the matrix <span class="process-math">\(A\)</span> has the singular value decomposition</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\begin{bmatrix}
-0.46 \amp 0.52 \amp 0.46 \amp 0.55 \\
-0.82 \amp 0.00 \amp -0.14 \amp -0.55 \\
-0.04 \amp 0.44 \amp -0.85 \amp 0.28 \\
-0.34 \amp -0.73 \amp -0.18 \amp 0.55
\end{bmatrix}
\begin{bmatrix}
6.2 \amp 0.0 \amp 0.0 \\
0.0 \amp 4.1 \amp 0.0 \\
0.0 \amp 0.0 \amp 0.0 \\
0.0 \amp 0.0 \amp 0.0
\end{bmatrix}
\begin{bmatrix}
-0.74 \amp 0.62 \amp -0.24 \\
0.28 \amp 0.62 \amp 0.73 \\
-0.61 \amp -0.48 \amp 0.64
\end{bmatrix}.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5572"><p id="p-8040">What are the dimensions of <span class="process-math">\(A\text{?}\)</span></p></li>
<li id="li-5573"><p id="p-8041">What is <span class="process-math">\(\rank(A)\text{?}\)</span></p></li>
<li id="li-5574"><p id="p-8042">Find orthonormal bases for <span class="process-math">\(\col(A)\text{,}\)</span> <span class="process-math">\(\nul(A)\text{,}\)</span> <span class="process-math">\(\col(A^T)\text{,}\)</span> and <span class="process-math">\(\nul(A^T)\text{.}\)</span></p></li>
<li id="li-5575"><p id="p-8043">Find the orthogonal projection of <span class="process-math">\(\bvec=\fourvec102{-1}\)</span> onto <span class="process-math">\(\col(A)\text{.}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-279"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<p id="p-8054">Consider the matrix <span class="process-math">\(A = \begin{bmatrix}
1 \amp 0 \amp -1 \\
2 \amp 2 \amp 0 \\
-1 \amp 1 \amp 2\\
\end{bmatrix}
\text{.}\)</span> <pre class="ptx-sagecell sagecell-sage" id="sage-243"><script type="text/x-sage">
</script></pre></p>
<ol class="lower-alpha">
<li id="li-5584"><p id="p-8055">Construct the Gram matrix <span class="process-math">\(G\)</span> and use it to find the singular values and right singular vectors <span class="process-math">\(\vvec_1\text{,}\)</span> <span class="process-math">\(\vvec_2\text{,}\)</span> and <span class="process-math">\(\vvec_3\)</span> of <span class="process-math">\(A\text{.}\)</span>  What are the matrices <span class="process-math">\(\Sigma\)</span> and <span class="process-math">\(V\)</span> in a singular value decomposition?</p></li>
<li id="li-5585"><p id="p-8056">What is <span class="process-math">\(\rank(A)\text{?}\)</span></p></li>
<li id="li-5586"><p id="p-8057">Find as many left singular <span class="process-math">\(\uvec_j\)</span> as you can using the relationship <span class="process-math">\(A\vvec_j=\sigma_j\uvec_j\text{.}\)</span></p></li>
<li id="li-5587"><p id="p-8058">Find an orthonormal basis for <span class="process-math">\(\nul(A^T)\)</span> and use it to construct the matrix <span class="process-math">\(U\)</span> so that <span class="process-math">\(A=U\Sigma
V^T\text{.}\)</span></p></li>
<li id="li-5588"><p id="p-8059">State an orthonormal basis for <span class="process-math">\(\nul(A)\)</span> and an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-280"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<p id="p-8070">Consider the matrix <span class="process-math">\(B=\begin{bmatrix}
1 \amp 0 \\
2 \amp -1 \\
1 \amp 2
\end{bmatrix}\)</span> and notice that <span class="process-math">\(B=A^T\)</span> where <span class="process-math">\(A\)</span> is the matrix in <a href="" class="xref" data-knowl="./knowl/ex-7-4-1.html" title="Exercise 7.4.5.1">Exercise 7.4.5.1</a>. <pre class="ptx-sagecell sagecell-sage" id="sage-244"><script type="text/x-sage">
</script></pre></p>
<ol class="lower-alpha">
<li id="li-5599"><p id="p-8071">Use your result from <a href="" class="xref" data-knowl="./knowl/ex-7-4-1.html" title="Exercise 7.4.5.1">Exercise 7.4.5.1</a> to find a singular value decomposition of <span class="process-math">\(B=U\Sigma V^T\text{.}\)</span></p></li>
<li id="li-5600"><p id="p-8072">What is <span class="process-math">\(\rank(B)\text{?}\)</span>  Determine a basis for <span class="process-math">\(\col(B)\)</span> and <span class="process-math">\(\col(B)^\perp\text{.}\)</span></p></li>
<li id="li-5601"><p id="p-8073">Suppose that <span class="process-math">\(\bvec=\threevec{-3}47\text{.}\)</span>  Use the bases you found in the previous part of this exericse to write <span class="process-math">\(\bvec=\bhat+\bvec^\perp\text{,}\)</span> where <span class="process-math">\(\bhat\)</span> is in <span class="process-math">\(\col(B)\)</span> and <span class="process-math">\(\bvec^\perp\)</span> is in <span class="process-math">\(\col(B)^\perp\text{.}\)</span></p></li>
<li id="li-5602"><p id="p-8074">Find the least squares approximate solution to the equation <span class="process-math">\(B\xvec=\bvec\text{.}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-281"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<p id="p-8085">Suppose that <span class="process-math">\(A\)</span> is a square <span class="process-math">\(m\times m\)</span> matrix with singular value decomposition <span class="process-math">\(A=U\Sigma V^T\text{.}\)</span></p>
<ol class="lower-alpha">
<li id="li-5611"><p id="p-8086">If <span class="process-math">\(A\)</span> is invertible, find a singular value decomposition of <span class="process-math">\(A^{-1}\text{.}\)</span></p></li>
<li id="li-5612"><p id="p-8087">What condition on the singular values must hold for <span class="process-math">\(A\)</span> to be invertible?</p></li>
<li id="li-5613"><p id="p-8088">How are the singular values of <span class="process-math">\(A\)</span> and the singular values of <span class="process-math">\(A^{-1}\)</span> related to one another?</p></li>
<li id="li-5614"><p id="p-8089">How are the right and left singular vectors of <span class="process-math">\(A\)</span> related to the right and left singular vectors of <span class="process-math">\(A^{-1}\text{?}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-282"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<ol id="p-8100" class="lower-alpha">
<li id="li-5623"><p id="p-8101">If <span class="process-math">\(Q\)</span> is an orthogonal matrix, remember that <span class="process-math">\(Q^TQ=I\text{.}\)</span>  Explain why <span class="process-math">\(\det Q = \pm 1\text{.}\)</span></p></li>
<li id="li-5624"><p id="p-8102">If <span class="process-math">\(A=U\Sigma V^T\)</span> is a singular value decomposition of a square matrix <span class="process-math">\(A\text{,}\)</span> explain why <span class="process-math">\(|\det A|\)</span> is the product of the singular values of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-5625"><p id="p-8103">What does this say about the singular values of <span class="process-math">\(A\)</span> if <span class="process-math">\(A\)</span> is invertible?</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-283"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<p id="p-8112">If <span class="process-math">\(A\)</span> is a matrix and <span class="process-math">\(G=A^TA\)</span> its Gram matrix, remember that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\xvec\cdot(G\xvec) = 
\xvec\cdot(A^TA\xvec) =
(A\xvec)\cdot(A\xvec) = \len{A\xvec}^2.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5632"><p id="p-8113">For a general matrix <span class="process-math">\(A\text{,}\)</span> explain why the eigenvalues of <span class="process-math">\(G\)</span> are nonnegative.</p></li>
<li id="li-5633"><p id="p-8114">Given a symmetric matrix <span class="process-math">\(A\)</span> having an eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> explain why <span class="process-math">\(\lambda^2\)</span> is an eigenvalue of <span class="process-math">\(G\text{.}\)</span></p></li>
<li id="li-5634"><p id="p-8115">If <span class="process-math">\(A\)</span> is symmetric, explain why the singular values of <span class="process-math">\(A\)</span> equal the absolute value of its eigenvalues:  <span class="process-math">\(\sigma_j = |\lambda_j|\text{.}\)</span></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-284"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<p id="p-8124">Determine whether the following statements are true or false and explain your reasoning.</p>
<ol class="lower-alpha">
<li id="li-5641"><p id="p-8125">If <span class="process-math">\(A=U\Sigma V^T\)</span> is a singular value decomposition of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(G=V(\Sigma^T\Sigma)V^T\)</span> is an orthogonal diagonalization of its Gram matrix.</p></li>
<li id="li-5642"><p id="p-8126">If <span class="process-math">\(A=U\Sigma V^T\)</span> is a singular value decomposition of a rank 2 matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> form an orthonormal basis for the column space <span class="process-math">\(\col(A)\text{.}\)</span></p></li>
<li id="li-5643"><p id="p-8127">If <span class="process-math">\(A\)</span> is a symmetric matrix, then its set of singular values is the same as its set of eigenvalues.</p></li>
<li id="li-5644"><p id="p-8128">If <span class="process-math">\(A\)</span> is a <span class="process-math">\(10\times7\)</span> matrix and <span class="process-math">\(\sigma_7
= 4\text{,}\)</span> then the columns of <span class="process-math">\(A\)</span> are linearly independent.</p></li>
<li id="li-5645"><p id="p-8129">The Gram matrix is always orthogonally diagonalizable.</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-285"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<p id="p-8142">Suppose that <span class="process-math">\(A=U\Sigma V^T\)</span> is a singular value decomposition of the <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A\text{.}\)</span>  If <span class="process-math">\(\sigma_1,\ldots,\sigma_r\)</span> are the nonzero singular values, the general form of the matrix <span class="process-math">\(\Sigma\)</span> is</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\Sigma = 
\begin{bmatrix}
\sigma_1 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp \sigma_r \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \vdots \amp 0 \amp \vdots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
\end{bmatrix}.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5656"><p id="p-8143">If you know that the columns of <span class="process-math">\(A\)</span> are linearly independent, what more can you say about the form of <span class="process-math">\(\Sigma\text{?}\)</span></p></li>
<li id="li-5657"><p id="p-8144">If you know that the columns of <span class="process-math">\(A\)</span> span <span class="process-math">\(\real^m\text{,}\)</span> what more can you say about the form of <span class="process-math">\(\Sigma\text{?}\)</span></p></li>
<li id="li-5658"><p id="p-8145">If you know that the columns of <span class="process-math">\(A\)</span> are linearly independent and span <span class="process-math">\(\real^m\text{,}\)</span> what more can you say about the form of <span class="process-math">\(\Sigma\text{?}\)</span></p></li>
</ol></article></section></section></div></main>
</div>
</body>
</html>
