<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2021-06-18T15:33:45-04:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Finding eigenvalues and eigenvectors</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script src="https://sagecell.sagemath.org/embedded_sagecell.js"></script><script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    useLabelIds: true,
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore",
    processHtmlClass: "has_am",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script>$(function () {
    // Make *any* div with class 'sagecell-sage' an executable Sage cell
    // Their results will be linked, only within language type
    sagecell.makeSagecell({inputLocation: 'div.sagecell-sage',
                           linked: true,
                           languages: ['sage'],
                           evalButtonText: 'Evaluate (Sage)'});
});
</script><script async="" src="https://cse.google.com/cse.js?cx=015103900096539427448:ngwuia10qci"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext_add_on.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script xmlns:svg="http://www.w3.org/2000/svg">sagecellEvalName='Evaluate (Sage)';
</script><link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext_add_on.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/banner_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/toc_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/knowls_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/style_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link xmlns:svg="http://www.w3.org/2000/svg" href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div xmlns:svg="http://www.w3.org/2000/svg" id="latex-macros" class="hidden-content" style="display:none">\(\newcommand{\avec}{{\mathbf a}}
\newcommand{\bvec}{{\mathbf b}}
\newcommand{\cvec}{{\mathbf c}}
\newcommand{\dvec}{{\mathbf d}}
\newcommand{\dtil}{\widetilde{\mathbf d}}
\newcommand{\evec}{{\mathbf e}}
\newcommand{\fvec}{{\mathbf f}}
\newcommand{\nvec}{{\mathbf n}}
\newcommand{\pvec}{{\mathbf p}}
\newcommand{\qvec}{{\mathbf q}}
\newcommand{\svec}{{\mathbf s}}
\newcommand{\tvec}{{\mathbf t}}
\newcommand{\uvec}{{\mathbf u}}
\newcommand{\vvec}{{\mathbf v}}
\newcommand{\wvec}{{\mathbf w}}
\newcommand{\xvec}{{\mathbf x}}
\newcommand{\yvec}{{\mathbf y}}
\newcommand{\zvec}{{\mathbf z}}
\newcommand{\rvec}{{\mathbf r}}
\newcommand{\mvec}{{\mathbf m}}
\newcommand{\zerovec}{{\mathbf 0}}
\newcommand{\onevec}{{\mathbf 1}}
\newcommand{\real}{{\mathbb R}}
\newcommand{\twovec}[2]{\left[\begin{array}{r}#1 \\ #2
\end{array}\right]}
\newcommand{\ctwovec}[2]{\left[\begin{array}{c}#1 \\ #2
\end{array}\right]}
\newcommand{\threevec}[3]{\left[\begin{array}{r}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\cthreevec}[3]{\left[\begin{array}{c}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\fourvec}[4]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\cfourvec}[4]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\fivevec}[5]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\cfivevec}[5]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\mattwo}[4]{\left[\begin{array}{rr}#1 \amp #2 \\ #3 \amp #4 \\ \end{array}\right]}
\newcommand{\laspan}[1]{\text{Span}\{#1\}}
\newcommand{\bcal}{{\cal B}}
\newcommand{\ccal}{{\cal C}}
\newcommand{\scal}{{\cal S}}
\newcommand{\wcal}{{\cal W}}
\newcommand{\ecal}{{\cal E}}
\newcommand{\coords}[2]{\left\{#1\right\}_{#2}}
\newcommand{\gray}[1]{\color{gray}{#1}}
\newcommand{\lgray}[1]{\color{lightgray}{#1}}
\newcommand{\rank}{\text{rank}}
\newcommand{\row}{\text{Row}}
\newcommand{\col}{\text{Col}}
\renewcommand{\row}{\text{Row}}
\newcommand{\nul}{\text{Nul}}
\newcommand{\var}{\text{Var}}
\newcommand{\corr}{\text{corr}}
\newcommand{\len}[1]{\left|#1\right|}
\newcommand{\bbar}{\overline{\bvec}}
\newcommand{\bhat}{\widehat{\bvec}}
\newcommand{\bperp}{\bvec^\perp}
\newcommand{\xhat}{\widehat{\xvec}}
\newcommand{\vhat}{\widehat{\vvec}}
\newcommand{\uhat}{\widehat{\uvec}}
\newcommand{\what}{\widehat{\wvec}}
\newcommand{\Sighat}{\widehat{\Sigma}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="ula.html"><span class="title">Understanding Linear Algebra</span></a></h1>
<p class="byline">David Austin</p>
</div>
<div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
</div></div>
<nav xmlns:svg="http://www.w3.org/2000/svg" id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="index-button toolbar-item button" href="index-1.html" title="Index">Index</a><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="sec-eigen-intro.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="chap4.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="sec-eigen-diag.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="sec-eigen-intro.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="chap4.html" title="Up">Up</a><a class="next-button button toolbar-item" href="sec-eigen-diag.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div xmlns:svg="http://www.w3.org/2000/svg" id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter.html" data-scroll="frontmatter"><span class="title">Front Matter</span></a><ul>
<li><a href="dedication-1.html" data-scroll="dedication-1">Dedication</a></li>
<li><a href="colophon-1.html" data-scroll="colophon-1">Colophon</a></li>
<li><a href="preface-1.html" data-scroll="preface-1">Our goals</a></li>
</ul>
</li>
<li class="link">
<a href="chap1.html" data-scroll="chap1"><span class="codenumber">1</span> <span class="title">Systems of equations</span></a><ul>
<li><a href="sec-expect.html" data-scroll="sec-expect">What can we expect</a></li>
<li><a href="sec-finding-solutions.html" data-scroll="sec-finding-solutions">Finding solutions to systems of linear equations</a></li>
<li><a href="sec-sage-introduction.html" data-scroll="sec-sage-introduction">Computation with Sage</a></li>
<li><a href="sec-pivots.html" data-scroll="sec-pivots">Pivots and their influence on solution spaces</a></li>
</ul>
</li>
<li class="link">
<a href="chap2.html" data-scroll="chap2"><span class="codenumber">2</span> <span class="title">Vectors, matrices, and linear combinations</span></a><ul>
<li><a href="sec-vectors-lin-combs.html" data-scroll="sec-vectors-lin-combs">Vectors and linear combinations</a></li>
<li><a href="sec-matrices-lin-combs.html" data-scroll="sec-matrices-lin-combs">Matrix multiplication and linear combinations</a></li>
<li><a href="sec-span.html" data-scroll="sec-span">The span of a set of vectors</a></li>
<li><a href="sec-linear-dep.html" data-scroll="sec-linear-dep">Linear independence</a></li>
<li><a href="sec-linear-trans.html" data-scroll="sec-linear-trans">Matrix transformations</a></li>
<li><a href="sec-transforms-geom.html" data-scroll="sec-transforms-geom">The geometry of matrix transformations</a></li>
</ul>
</li>
<li class="link">
<a href="chap3.html" data-scroll="chap3"><span class="codenumber">3</span> <span class="title">Invertibility, bases, and coordinate systems</span></a><ul>
<li><a href="sec-matrix-inverse.html" data-scroll="sec-matrix-inverse">Invertibility</a></li>
<li><a href="sec-bases.html" data-scroll="sec-bases">Bases and coordinate systems</a></li>
<li><a href="sec-jpeg.html" data-scroll="sec-jpeg">Image compression</a></li>
<li><a href="sec-determinants.html" data-scroll="sec-determinants">Determinants</a></li>
<li><a href="sec-subspaces.html" data-scroll="sec-subspaces">Subspaces of \(\real^p\)</a></li>
</ul>
</li>
<li class="link">
<a href="chap4.html" data-scroll="chap4"><span class="codenumber">4</span> <span class="title">Eigenvalues and eigenvectors</span></a><ul>
<li><a href="sec-eigen-intro.html" data-scroll="sec-eigen-intro">An introduction to eigenvalues and eigenvectors</a></li>
<li><a href="sec-eigen-find.html" data-scroll="sec-eigen-find" class="active">Finding eigenvalues and eigenvectors</a></li>
<li><a href="sec-eigen-diag.html" data-scroll="sec-eigen-diag">Diagonalization, similarity, and powers of a matrix</a></li>
<li><a href="sec-dynamical.html" data-scroll="sec-dynamical">Dynamical systems</a></li>
<li><a href="sec-stochastic.html" data-scroll="sec-stochastic">Markov chains and Google's PageRank algorithm</a></li>
</ul>
</li>
<li class="link">
<a href="chap5.html" data-scroll="chap5"><span class="codenumber">5</span> <span class="title">Linear algebra and computing</span></a><ul>
<li><a href="sec-gaussian-revisited.html" data-scroll="sec-gaussian-revisited">Gaussian elimination revisited</a></li>
<li><a href="sec-power-method.html" data-scroll="sec-power-method">Finding eigenvectors numerically</a></li>
</ul>
</li>
<li class="link">
<a href="chap6.html" data-scroll="chap6"><span class="codenumber">6</span> <span class="title">Orthogonality and Least Squares</span></a><ul>
<li><a href="sec-dot-product.html" data-scroll="sec-dot-product">The dot product</a></li>
<li><a href="sec-transpose.html" data-scroll="sec-transpose">Orthogonal complements and the matrix tranpose</a></li>
<li><a href="sec-orthogonal-bases.html" data-scroll="sec-orthogonal-bases">Orthogonal bases and projections</a></li>
<li><a href="sec-gram-schmidt.html" data-scroll="sec-gram-schmidt">Finding orthogonal bases</a></li>
<li><a href="sec-least-squares.html" data-scroll="sec-least-squares">Orthogonal least squares</a></li>
</ul>
</li>
<li class="link">
<a href="chap7.html" data-scroll="chap7"><span class="codenumber">7</span> <span class="title">The Spectral Theorem and singular value decompositions</span></a><ul>
<li><a href="sec-symmetric-matrices.html" data-scroll="sec-symmetric-matrices">Symmetric matrices and variance</a></li>
<li><a href="sec-quadratic-forms.html" data-scroll="sec-quadratic-forms">Quadratic forms</a></li>
<li><a href="sec-pca.html" data-scroll="sec-pca">Principal Component Analysis</a></li>
<li><a href="sec-svd-intro.html" data-scroll="sec-svd-intro">Singular Value Decompositions</a></li>
<li><a href="sec-svd-uses.html" data-scroll="sec-svd-uses">Using Singular Value Decompositions</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter.html" data-scroll="backmatter"><span class="title">Back Matter</span></a></li>
<li class="link"><a href="index-1.html" data-scroll="index-1"><span class="title">Index</span></a></li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section xmlns:svg="http://www.w3.org/2000/svg" class="section" id="sec-eigen-find"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.2</span> <span class="title">Finding eigenvalues and eigenvectors</span>
</h2>
<section class="introduction" id="introduction-20"><p id="p-3668">The last section introduced eigenvalues and eigenvectors, presented the underlying geometric intuition behind their definition, and demonstrated their use in understanding the long-term behavior of certain systems.  We will now develop a more algebraic understanding of eigenvalues and eigenvectors.  In particular, we will find an algebraic method for determining the eigenvalues and eigenvectors of a square matrix.</p>
<article class="exploration project-like" id="exploration-15"><h6 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">4.2.1</span><span class="period">.</span>
</h6>
<p id="p-3669">Let's begin by reviewing some important ideas that we have seen previously.</p>
<ol class="lower-alpha">
<li id="li-2482"><p id="p-3670">Suppose that \(A\) is a square matrix and that the nonzero vector \(\xvec\) is a solution to the homogeneous equation \(A\xvec = \zerovec\text{.}\)  What can we conclude about the invertibility of \(A\text{?}\)</p></li>
<li id="li-2483"><p id="p-3671">How does the determinant \(\det A\) tell us if there is a nonzero solution to the homogeneous equation \(A\xvec = \zerovec\text{?}\)</p></li>
<li id="li-2484">
<p id="p-3672">Suppose that</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rrr}
3 \amp -1 \amp 1 \\
0 \amp 2 \amp 4 \\
1 \amp 1 \amp 3 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p class="continuation">Find the determinant \(\det A\text{.}\)  What does this tell us about the solution space to the homogeneous equation \(A\xvec
= \zerovec\text{?}\)</p>
</li>
<li id="li-2485"><p id="p-3673">FInd a basis for \(\nul(A)\text{.}\)</p></li>
<li id="li-2486"><p id="p-3674">What is the relationship between the rank of a matrix and the dimension of its null space?</p></li>
</ol></article></section><section class="subsection" id="subsection-58"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.2.1</span> <span class="title">The characteristic polynomial</span>
</h3>
<p id="p-3681">We will first see that the eigenvalues of a square matrix appear as the roots of a particular polynomial.  To begin, notice that we originally defined an eigenvector as a nonzero vector \(\vvec\) that satisfied the equation \(A\vvec =
\lambda\vvec\text{.}\)  We will rewrite this as</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
A\vvec \amp {}={} \lambda\vvec \\
A\vvec - \lambda\vvec \amp {}={} \zerovec \\
A\vvec - \lambda I\vvec \amp {}={} \zerovec \\
(A-\lambda I)\vvec \amp {}={} \zerovec\text{.} \\
\end{aligned}
\end{equation*}
</div>
<p class="continuation">In other words, an eigenvector \(\vvec\) is a solution of the homogeneous equation \((A-\lambda I)\vvec=\zerovec\text{.}\)  This puts us in familiar territory, which we will explore in the next activity.</p>
<article class="activity project-like" id="activity-43"><h6 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">4.2.2</span><span class="period">.</span>
</h6>
<p id="p-3682">The eigenvalues of a square matrix are defined by the condition that there be a nonzero solution to the homogeneous equation \((A-\lambda I)\vvec=\zerovec\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2492"><p id="p-3683">If there is a nonzero solution to the homogeneous equation \((A-\lambda I)\vvec = \zerovec\text{,}\) what can we conclude about the invertibility of the matrix \(A-\lambda
I\text{?}\)</p></li>
<li id="li-2493"><p id="p-3684">If there is a nonzero solution to the homogeneous equation \((A-\lambda I)\vvec = \zerovec\text{,}\) what can we conclude about the determinant \(\det(A-\lambda I)\text{?}\)</p></li>
<li id="li-2494">
<p id="p-3685">Let's consider the matrix</p>
<div class="displaymath">
\begin{equation*}
A = \left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]
\end{equation*}
</div>
<p class="continuation">from which we construct</p>
<div class="displaymath">
\begin{equation*}
A-\lambda I =
\left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]
- \lambda 
\left[\begin{array}{rr}
1 \amp 0 \\
0 \amp 1 \\
\end{array}\right]
=
\left[\begin{array}{rr}
1-\lambda \amp 2 \\
2 \amp 1-\lambda \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p class="continuation">Find the determinant \(\det(A-\lambda I)\text{.}\)  What kind of equation do you obtain when we set this determinant to zero to obtain \(\det(A-\lambda I) = 0\text{?}\)</p>
</li>
<li id="li-2495"><p id="p-3686">Use the determinant you found in the previous part to find the eigenvalues \(\lambda\) by solving \(\det(A-\lambda I) = 0\text{.}\)  We considered this matrix in the previous section so we should find the same eigenvalues for \(A\) that we found by reasoning geometrically there.</p></li>
<li id="li-2496"><p id="p-3687">Consider the matrix \(A = \left[\begin{array}{rr}
2 \amp 1 \\
0 \amp 2 \\
\end{array}\right]\) and find its eigenvalues by solving the equation \(\det(A-\lambda I) = 0\text{.}\)</p></li>
<li id="li-2497"><p id="p-3688">Consider the matrix \(A = \left[\begin{array}{rr}
0 \amp -1 \\
1 \amp 0 \\
\end{array}\right]\) and find its eigenvalues by solving the equation \(\det(A-\lambda I) = 0\text{.}\)</p></li>
<li id="li-2498"><p id="p-3689">Find the eigenvalues of the triangular matrix \(\left[\begin{array}{rrr}
3 \amp -1 \amp 4 \\
0 \amp -2 \amp 3 \\
0 \amp 0 \amp 1 \\
\end{array}\right]
\text{.}\)  What is generally true about the eigenvalues of a triangular matrix?</p></li>
</ol></article><p id="p-3691">This activity demonstrates a technique that enables us to find the eigenvalues of a square matrix \(A\text{.}\)  Since an eigenvalue \(\lambda\) is a scalar for which the equation \((A-\lambda
I)\vvec = \zerovec\) has a nonzero solution, it must be the case that \(A-\lambda I\) is not invertible.  Therefore, its determinant is zero.  This gives us the equation</p>
<div class="displaymath">
\begin{equation*}
\det(A-\lambda I) = 0
\end{equation*}
</div>
<p class="continuation">whose solutions are the eigenvalues of \(A\text{.}\)  This equation is called the <em class="emphasis">characteristic equation</em> of \(A\text{.}\) </p>
<p id="p-3692">If we write the characteristic equation for the matrix \(A = \left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]
\text{,}\) we see that</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
\det(A-\lambda I) \amp {}={} 0 \\
\\
\det \left[\begin{array}{rr}
1 - \lambda \amp 2 \\
2 \amp 1 - \lambda \\
\end{array}\right] \amp {}={} 0 \\
\\
(1-\lambda)^2 - 4 \amp {}={}  0 \\
-3 - 2\lambda + \lambda^2 {}={} 0 \\
(3-\lambda)(-1-\lambda) {}={} 0\text{.} \\
\end{aligned}
\end{equation*}
</div>
<p class="continuation">This shows us that the eigenvalues are \(\lambda = 3\) and \(\lambda=-1\text{,}\) the same eigenvalues we found by reasoning geometrically in the previous section.</p>
<p id="p-3693"> In general, the expression \(\det(A-\lambda I)\) is a polynomial in \(\lambda\text{,}\) which is called the <em class="emphasis">characteristic polynomial</em> of \(A\text{.}\)  If \(A\) is an \(n\times n\) matrix, the degree of the characteristic polynomial is \(n\text{.}\)  For instance, if \(A\) is a \(2\times2\) matrix, then \(\det(A-\lambda I)\) is a quadratic polynomial; if \(A\) is a \(3\times3\) matrix, then \(\det(A-\lambda I)\) is a cubic polynomial.</p>
<p id="p-3694">The other examples that appear in this activity demonstrate some issues we will need to deal with later.  For instance, the matrix \(A = \left[\begin{array}{rr}
2 \amp 1 \\
0 \amp 2 \\
\end{array}\right]\) leads to the characteristic equation, \((2-\lambda)^2 = 0\text{.}\) In this case, there is only one eigenvalue \(\lambda = 2\) that appears as a repeated root.  For now, we simply note that our work in the previous section showed that it was not possible to form a basis of \(\real^2\) consisting of eigenvectors of \(A\text{.}\)</p>
<p id="p-3695">Finally, when \(A = \left[\begin{array}{rr}
0 \amp -1 \\
1 \amp 0 \\
\end{array}\right]
\text{,}\) we find the characteristic equation \(\lambda^2 + 1 =
0\text{.}\)  While this equation has no real solutions, it does have complex solutions \(\lambda = \pm i\text{,}\) and it will be useful for us to work with these complex eigenvalues in the future.  In the meantime, remember that this matrix defines a \(90^\circ\) rotation so we do not expect any solutions to the equation \(A\vvec = \lambda \vvec\) for real eigenvalues \(\lambda\) since a vector \(\vvec\) and \(A\vvec\) can never lie on the same line.</p>
<p id="p-3696">Finally, the eigenvalues of a triangular matrix are easily determined because the determinant of a triangular matrix is the product of the entries on the diagonal.  Therefore, the characteristic equation is</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
\det\left(
\left[\begin{array}{rrr}
3 \amp -1 \amp 4 \\
0 \amp -2 \amp 3 \\
0 \amp 0 \amp 1 \\
\end{array}\right]
-\lambda I\right) \amp {}={}
\det
\left[\begin{array}{rrr}
3-\lambda \amp -1 \amp 4 \\
0 \amp -2-\lambda \amp 3 \\
0 \amp 0 \amp 1-\lambda \\
\end{array}\right] \\
\\
\amp {}={}(3-\lambda)(-2-\lambda)(1-\lambda) = 0\text{,}
\end{aligned}
\end{equation*}
</div>
<p class="continuation">showing that the eigenvalues are the diagonal entries \(\lambda =
3,-2,1\text{.}\)</p>
<p id="p-3697">We have how seen now the characteristic equation can be used to determine the eigenvalues of a matrix.  Remember, however, that finding the determinant of a matrix using a co-factor expansion is not computationally feasible when the size of the matrix is relatively large.  Finding the eigenvalues of a matrix by factoring its characteristic polynomial is therefore a technique limited to relatively small matrices; we will introduce a new technique for finding eigenvalues of larger matrices in the next chapter.</p></section><section class="subsection" id="subsection-59"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.2.2</span> <span class="title">Finding eigenvectors</span>
</h3>
<p id="p-3698">Now that we can find the eigenvalues of a square matrix \(A\) by solving the characteristic equation \(\det(A-\lambda
I) = 0\text{,}\) we will turn to the question of finding the eigenvectors associated to an eigenvalue \(\lambda\text{.}\) Once again, the key is to note that an eigenvector is a nonzero solution to the homogeneous equation \((A-\lambda I)\vvec =
\zerovec\text{.}\)  In other words, the eigenvectors associated to an eigenvalue \(\lambda\) form the null space \(\nul(A-\lambda
I)\text{.}\)</p>
<p id="p-3699">This shows that the eigenvectors associated to an eigenvalue form a subspace of \(\real^n\text{.}\)  We will use \(E_\lambda\) to denote the subspace of eigenvectors of a matrix \(A\) associated to the eigenvalue \(\lambda\) and note that</p>
<div class="displaymath">
\begin{equation*}
E_\lambda = \nul(A-\lambda I)\text{.}
\end{equation*}
</div>
<p class="continuation">We say that \(E_\lambda\) is the <em class="emphasis">eigenspace</em> of \(A\) associated to the eigenvalue \(\lambda\text{.}\) </p>
<article class="activity project-like" id="activity-44"><h6 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">4.2.3</span><span class="period">.</span>
</h6>
<p id="p-3700">In this activity, we will find the eigenvectors of a matrix as the null space of the matrix \(A-\lambda I\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2499"><p id="p-3701">Let's begin with the matrix \(A = \left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]
\text{.}\)  We have seen that \(\lambda = 3\) is an eigenvalue. Form the matrix \(A-3I\) and find a basis for the eigenspace \(E_3 = \nul(A-3I)\text{.}\) What is the dimension of this eigenspace? For each of the basis vectors \(\vvec\text{,}\) verify that \(A\vvec = 3\vvec\text{.}\)</p></li>
<li id="li-2500"><p id="p-3702">We also saw that \(\lambda = -1\) is an eigenvalue.  Form the matrix \(A-(-1)I\) and find a basis for the eigenspace \(E_{-1}\text{.}\)  What is the dimension of this eigenspace? For each of the basis vectors \(\vvec\text{,}\) verify that \(A\vvec = -\vvec\text{.}\)</p></li>
<li id="li-2501"><p id="p-3703">Is it possible to form a basis of \(\real^2\) consisting of eigenvectors of \(A\text{?}\)</p></li>
<li id="li-2502"><p id="p-3704">Now consider the matrix \(A = \left[\begin{array}{rr}
3 \amp 0 \\
0 \amp 3 \\
\end{array}\right]
\text{.}\)  Write the characteristic equation for \(A\) and use it to find the eigenvalues of \(A\text{.}\)  For each eigenvalue, find a basis for its eigenspace \(E_\lambda\text{.}\)  Is it possible to form a basis of \(\real^2\) consisting of eigenvectors of \(A\text{?}\)</p></li>
<li id="li-2503"><p id="p-3705">Next, consider the matrix \(A = \left[\begin{array}{rr}
2 \amp 1 \\
0 \amp 2 \\
\end{array}\right]
\text{.}\)  Write the characteristic equation for \(A\) and use it to find the eigenvalues of \(A\text{.}\)  For each eigenvalue, find a basis for its eigenspace \(E_\lambda\text{.}\)  Is it possible to form a basis of \(\real^2\) consisting of eigenvectors of \(A\text{?}\)</p></li>
<li id="li-2504"><p id="p-3706">Finally, find the eigenvalues and eigenvectors of the diagonal matrix \(A = \left[\begin{array}{rr}
4 \amp 0 \\
0 \amp -1 \\
\end{array}\right]
\text{.}\)  Explain your result by considering the geometric effect of the matrix transformation defined by \(A\text{.}\)</p></li>
</ol></article><p id="p-3714">Once we find the eigenvalues of a matrix \(A\text{,}\) describing the eigenspace \(E_\lambda\) amounts to the familiar task of describing the null space \(\nul(A-\lambda I)\text{.}\)  For instance, we know that \(\lambda = 3\) is an eigenvalue of \(A = \left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]
\text{.}\) Then, \(E_3 = \nul(A-3I)\text{,}\) and we have</p>
<div class="displaymath">
\begin{equation*}
A - 3I =
\left[\begin{array}{rr}
-2 \amp 2 \\
2 \amp -2 \\
\end{array}\right]
\sim
\left[\begin{array}{rr}
1 \amp -1 \\
0 \amp 0 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p class="continuation">From the reduced row echelon form, we see that the eigenvectors \(\vvec = \twovec{v_1}{v_2}\) are determined by the single equation \(v_1-v_2 = 0\) or \(v_1 = v_2\text{.}\)  Therefore the eigenvectors in \(E_3\) have the form</p>
<div class="displaymath">
\begin{equation*}
\vvec=\twovec{v_1}{v_2} = \twovec{v_2}{v_2} = v_2\twovec{1}{1}\text{.}
\end{equation*}
</div>
<p class="continuation">In other words, \(E_3\) is a one-dimensional subspace of \(\real^2\) with basis \(\twovec{1}{1}\text{.}\)  Once again, this agrees with the eigenvectors that we found geometrically in the previous section.</p>
<p id="p-3715">The same reasoning applies to show that the eigenvectors associated to \(\lambda = -1\) have the form</p>
<div class="displaymath">
\begin{equation*}
\vvec = v_2\twovec{-1}{1}\text{,}
\end{equation*}
</div>
<p class="continuation">which shows that the eigenspace \(E_{-1}\) is a one-dimensional subspace of \(\real^2\) having basis \(\twovec{-1}{1}\text{.}\)</p>
<p id="p-3716">Two more examples from the activity are important.  The characteristic equation for the matrix \(A=
\left[\begin{array}{rr}
3 \amp 0 \\
0 \amp 3 \\
\end{array}\right]\) is \(\det(A-\lambda I) = (3-\lambda)^2 = 0\text{.}\)  This shows that there is a single eigenvalue \(\lambda = 3\text{.}\)  If we find the eigenspace \(E_3=\nul(A-3I)\text{,}\) we have</p>
<div class="displaymath">
\begin{equation*}
A -3I = 
\left[\begin{array}{rr}
3 \amp 0 \\
0 \amp 3 \\
\end{array}\right]
- 3I
=
\left[\begin{array}{rr}
0 \amp 0 \\
0 \amp 0 \\
\end{array}\right]\text{.}
\end{equation*}
</div>
<p class="continuation">This shows that every vector is in \(E_3\) so that \(E_3=\real^2\text{.}\)  In this case, there is a basis of \(\real^2\) consisting of eigenvectors of \(A\text{.}\)  This aligns with our geometric understanding:  this matrix has the effect of scaling vectors by a factor of \(3\) in every direction. Therefore, every vector is an eigenvector with eigenvalue \(\lambda = 3\text{.}\)</p>
<p id="p-3717">However, if we consider the matrix \(A=
\left[\begin{array}{rr}
2 \amp 1 \\
0 \amp 2 \\
\end{array}\right]
\text{,}\) we find the characteristic equation \((2-\lambda)^2 = 0\text{,}\) which shows that there is again a single eigenvalue \(\lambda =
2\text{.}\)  In this case,</p>
<div class="displaymath">
\begin{equation*}
A -2I = 
\left[\begin{array}{rr}
2 \amp 1 \\
0 \amp 2 \\
\end{array}\right]
- 2I
=
\left[\begin{array}{rr}
0 \amp 1 \\
0 \amp 0 \\
\end{array}\right]\text{,}
\end{equation*}
</div>
<p class="continuation">which shows that \(E_2\) is a one-dimensional subspace of \(\real^2\) with basis \(\twovec{1}{0}\text{.}\)  Since there are no other eigenvalues, it is not possible to find a basis for \(\real^2\) consisting of eigenvectors of \(A\text{.}\)</p>
<p id="p-3718">Once again, we can understand this result geometrically.  The matrix transformation corresponding to the matrix \(A\) is a shear that slides vectors horizontally.  This transformation therefore only scales vectors that lie on the horizontal axis.</p>
<p id="p-3719">These last two examples illustrate two types of behavior when there is a single eigenvalue.  In one case, we are able to construct a basis of \(\real^2\) using eigenvectors;  in the other, we are not. We will explore this behavior more in the next subsection.</p>
<article class="assemblage assemblage-like" id="assemblage-8"><h6 class="heading"><span class="title">A check on our work.</span></h6>
<p id="p-3720">When finding eigenvalues and their associated eigenvectors in this way, we first find eigenvalues \(\lambda\) by solving the characteristic equation.  If \(\lambda\) is a solution to the characteristic equation, then \(A-\lambda I\) is not invertible and, consequently, \(A-\lambda I\) must contain a row without a pivot position.</p>
<p id="p-3721">This serves as a check on our work.  If we row reduce \(A-\lambda I\) and find the identity matrix, then we have made an error either in solving the characteristic equation or in finding \(\nul(A-\lambda I)\text{.}\)</p></article></section><section class="subsection" id="subsection-60"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.2.3</span> <span class="title">The characteristic polynomial and the dimension of eigenspaces</span>
</h3>
<p id="p-3722">Given a square \(n\times n\) matrix \(A\text{,}\) we saw in the previous section the value of being able to express any vector in \(\real^n\) as a linear combination of eigenvectors of \(A\text{.}\)  For this reason, we asked <a class="xref" data-knowl="./knowl/question-eigen-basis.html" title="Question 4.1.7">Question 4.1.7</a> to determine when we can construct a basis of \(\real^n\) consisting of eigenvectors.  We will explore this question more fully now.</p>
<p id="p-3723">As we saw above, the eigenvalues of \(A\) are the solutions of the characteristic equation \(\det(A-\lambda I) = 0\text{.}\)  Two examples of characteristic equations we have seen above are</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
(3-\lambda)(-2-\lambda)(1-\lambda) \amp {}={} 0 \\
\text{and}\qquad(2-\lambda)^2 \amp {}={} 0 \\
\end{aligned}\text{.}
\end{equation*}
</div>
<p class="continuation">Generally speaking, the characteristic polynomial can always be factored into terms having the form \((\lambda_j-\lambda)\) where \(\lambda_j\) is an eigenvalue of \(A\text{.}\)  In doing so, we must allow ourselves to consider complex eigenvalues, which we will study in more detail in the next section.  This means, however, that we can always write the characteristic equation in the form</p>
<div class="displaymath">
\begin{equation*}
(\lambda_1-\lambda)^{m_1}
(\lambda_2-\lambda)^{m_2}
\ldots
(\lambda_p-\lambda)^{m_p}
= 0\text{.}
\end{equation*}
</div>
<p class="continuation">The solutions to the characteristic equation are the eigenvalues \(\lambda_j\text{,}\) and \(m_j\text{,}\) the number of times that \(\lambda_j - \lambda\) appears as a factor in the characteristic polynomial, is called the <em class="emphasis">multiplicity</em> of the eigenvalue \(\lambda_j\text{.}\) </p>
<article class="example example-like" id="example-18"><h6 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.2.1</span><span class="period">.</span>
</h6>
<p id="p-3724">We have seen that the matrix \(A = \left[\begin{array}{rr}
2 \amp 1 \\
0 \amp 2 \\
\end{array}\right]\) has the characteristic equation \((2-\lambda)^2 =
0\text{.}\)  This matrix \(A\) has a single eigenvalue \(\lambda = 2\text{,}\) which has multiplicity \(2\text{.}\)</p></article><article class="example example-like" id="example-19"><h6 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.2.2</span><span class="period">.</span>
</h6>
<p id="p-3725">If a matrix has the characteristic equation</p>
<div class="displaymath">
\begin{equation*}
(4-\lambda)^2(-5-\lambda)(1-\lambda)^7(3-\lambda)^2 = 0\text{,}
\end{equation*}
</div>
<p class="continuation">then that matrix has four eigenvalues:  \(\lambda=4\) having multiplicity 2; \(\lambda=-5\) having multiplicity 1; \(\lambda=1\) having multiplicty 7; and \(\lambda=3\) having multiplicty 2.  The degree of the characteristic polynomial is the sum of the multiplicities \(2+1+7+2 =
12\) so this matrix must be a \(12\times12\) matrix.</p></article><p id="p-3726">The multiplicities of the eigenvalues are important because they influence the dimension of the eigenspaces.  We know that the dimension of an eigenspace must be at least one; the following proposition also tells us the dimension of an eigenspace can be no larger than the multiplicity of its associated eigenvalue.</p>
<article class="proposition theorem-like" id="prop-eigen-basis"><h6 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">4.2.3</span><span class="period">.</span>
</h6>
<p id="p-3727">If \(\lambda\) is a real eigenvalue of the matrix \(A\) with multiplicity \(m\text{,}\) then</p>
<div class="displaymath">
\begin{equation*}
1 \leq \dim E_\lambda \leq m\text{.}
\end{equation*}
</div></article><article class="example example-like" id="example-20"><h6 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.2.4</span><span class="period">.</span>
</h6>
<p id="p-3728">The diagonal matrix \(\left[\begin{array}{rr}
3 \amp 0 \\
0 \amp 3 \\
\end{array}\right]\) has the characteristic equation \((3-\lambda)^2 =
0\text{.}\)  There is a single eigenvalue \(\lambda = 3\) having multiplicity \(m = 2\text{,}\) and we saw earlier that \(\dim E_3 = 2 \leq m = 2\text{.}\)</p></article><article class="example example-like" id="example-21"><h6 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.2.5</span><span class="period">.</span>
</h6>
<p id="p-3729">The matrix \(\left[\begin{array}{rr}
2 \amp 1 \\
0 \amp 2 \\
\end{array}\right]\) has the characteristic equation \((2-\lambda)^2 =
0\text{.}\)  Once again, there is a single eigenvalue \(\lambda =
2\) having multiplicity \(m = 2\text{.}\)  In contrast with the previous example, we saw that \(\dim E_2 = 1 \leq m = 2\text{.}\)</p></article><article class="example example-like" id="example-22"><h6 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.2.6</span><span class="period">.</span>
</h6>
<p id="p-3730">We saw earlier that the matrix \(\left[\begin{array}{rrr}
3 \amp -1 \amp 4 \\
0 \amp -2 \amp 3 \\
0 \amp 0 \amp 1 \\
\end{array}\right]\) has the characteristic equation</p>
<div class="displaymath">
\begin{equation*}
(3-\lambda)(-2-\lambda)(1-\lambda)=0\text{.}
\end{equation*}
</div>
<p class="continuation">There are three eigenvalues \(\lambda=3,-2,1\) each having multiplicity \(1\text{.}\)  By the proposition, we are guaranteed that the dimension of each eigenspace is \(1\text{;}\)  that is,</p>
<div class="displaymath">
\begin{equation*}
\dim E_3 = \dim E_{-2} = \dim E_1 = 1\text{.}
\end{equation*}
</div>
<p class="continuation">It turns out that this is enough to guarantee that there is a basis of \(\real^3\) consisting of eigenvectors.</p></article><article class="example example-like" id="example-23"><h6 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.2.7</span><span class="period">.</span>
</h6>
<p id="p-3731">If a \(12\times12\) matrix has the characteristic equation</p>
<div class="displaymath">
\begin{equation*}
(4-\lambda)^2(-5-\lambda)(1-\lambda)^7(3-\lambda)^2 = 0\text{,}
\end{equation*}
</div>
<p class="continuation">we know there are four eigenvalues \(\lambda=4,-5,1,3\text{.}\) Without more information, all we can say about the dimensions of the eigenspaces is</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
1 \leq \dim E_4 \amp {}\leq{} 2 \\
1 \leq \dim E_{-5} \amp {}\leq{} 1 \\
1 \leq \dim E_1 \amp {}\leq{} 7 \\
1 \leq \dim E_3 \amp {}\leq{} 2\text{.} \\
\end{aligned}
\end{equation*}
</div>
<p class="continuation">We can guarantee that \(\dim E_{-5} = 1\text{,}\) but we cannot be more specific about the dimensions of the other eigenspaces.</p></article><p id="p-3732">Fortunately, if we have an \(n\times n\) matrix, it most commonly happens that the characteristic equation has the form</p>
<div class="displaymath">
\begin{equation*}
(\lambda_1-\lambda)
(\lambda_2-\lambda)
\ldots
(\lambda_n-\lambda) = 0
\end{equation*}
</div>
<p class="continuation">where there are \(n\) distinct eigenvalues, each of which has multiplicity \(1\text{.}\)  In this case, the dimension of each of the eigenspaces \(\dim E_{\lambda_j} = 1\text{.}\)  With a little work, it can be seen that choosing a basis vector \(\vvec_j\) for each of the eigenspaces produces a basis for \(\real^n\text{.}\)  We therefore have the following proposition.</p>
<article class="proposition theorem-like" id="proposition-18"><h6 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">4.2.8</span><span class="period">.</span>
</h6>
<p id="p-3733">If \(A\) is an \(n\times n\) matrix having \(n\) distinct real eigenvalues, then there is a basis of \(\real^n\) consisting of eigenvectors of \(A\text{.}\)</p></article><p id="p-3734">This proposition provides one answer to our <a class="xref" data-knowl="./knowl/question-eigen-basis.html" title="Question 4.1.7">Question 4.1.7</a>.  The next activity explores this question further.</p>
<article class="activity project-like" id="activity-45"><h6 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">4.2.4</span><span class="period">.</span>
</h6>
<ol id="p-3735" class="lower-alpha">
<li id="li-2511"><p id="p-3736">Identify the eigenvalues, and their multiplicities, of an \(n\times n\) matrix whose characteristic polynomial is \((2-\lambda)^3(-3-\lambda)^{10}(5-\lambda)\text{.}\)  What can you conclude about the dimensions of the eigenspaces?  What is the dimension of the matrix?  Do you have enough information to guarantee that there is a basis of \(\real^n\) consisting of eigenvectors?</p></li>
<li id="li-2512"><p id="p-3737">Find the eigenvalues of \(\left[\begin{array}{rr}
0 \amp -1 \\
4 \amp -4 \\
\end{array}\right]\) and state their multiplicities.  Can you find a basis of \(\real^2\) consisting of eigenvectors of this matrix?</p></li>
<li id="li-2513">
<p id="p-3738">Consider the matrix \(A =
\left[\begin{array}{rrr}
-1 \amp 0 \amp 2 \\
-2 \amp -2 \amp -4 \\
0 \amp 0 \amp -2 \\
\end{array}\right]\) whose characteristic equation is</p>
<div class="displaymath">
\begin{equation*}
(-2-\lambda)^2(-1-\lambda) = 0\text{.}
\end{equation*}
</div>
<ol class="lower-roman">
<li id="li-2514"><p id="p-3739">Identify the eigenvalues and their multiplicities.</p></li>
<li id="li-2515"><p id="p-3740">For each eigenvalue \(\lambda\text{,}\) find a basis of the eigenspace \(E_\lambda\) and state its dimension.</p></li>
<li id="li-2516"><p id="p-3741">Is there a basis of \(\real^3\) consisting of eigenvectors of \(A\text{?}\)</p></li>
</ol>
</li>
<li id="li-2517">
<p id="p-3742">Now consider the matrix \(A =
\left[\begin{array}{rrr}
-5 \amp -2 \amp -6 \\
-2 \amp -2 \amp -4 \\
2 \amp 1 \amp 2 \\
\end{array}\right]\) whose characteristic equation is also</p>
<div class="displaymath">
\begin{equation*}
(-2-\lambda)^2(-1-\lambda) = 0\text{.}
\end{equation*}
</div>
<ol class="lower-roman">
<li id="li-2518"><p id="p-3743">Identify the eigenvalues and their multiplicities.</p></li>
<li id="li-2519"><p id="p-3744">For each eigenvalue \(\lambda\text{,}\) find a basis of the eigenspace \(E_\lambda\) and state its dimension.</p></li>
<li id="li-2520"><p id="p-3745">Is there a basis of \(\real^3\) consisting of eigenvectors of \(A\text{?}\)</p></li>
</ol>
</li>
<li id="li-2521">
<p id="p-3746">Consider the matrix \(A = 
\left[\begin{array}{rrr}
-5 \amp -2 \amp -6 \\
4 \amp 1 \amp 8 \\
2 \amp 1 \amp 2 \\
\end{array}\right]\) whose characteristic equation is</p>
<div class="displaymath">
\begin{equation*}
(-2-\lambda)(1-\lambda)(-1-\lambda) = 0\text{.}
\end{equation*}
</div>
<ol class="lower-roman">
<li id="li-2522"><p id="p-3747">Identify the eigenvalues and their multiplicities.</p></li>
<li id="li-2523"><p id="p-3748">For each eigenvalue \(\lambda\text{,}\) find a basis of the eigenspace \(E_\lambda\) and state its dimension.</p></li>
<li id="li-2524"><p id="p-3749">Is there a basis of \(\real^3\) consisting of eigenvectors of \(A\text{?}\)</p></li>
</ol>
</li>
</ol></article></section><section class="subsection" id="subsection-61"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.2.4</span> <span class="title">Computational issues in finding eigenvalues and eigenvectors</span>
</h3>
<p id="p-3766">We can use Sage to find the characteristic polynomial, eigenvalues, and eigenvectors of a matrix.  As we will see, however, some care is required when dealing with matrices whose entries include floating point numbers.  The next activity demonstrates how Sage can be used in this way and some of the complications that arise.  We will revisit this issue in subsequent sections.</p>
<article class="activity project-like" id="activity-46"><h6 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">4.2.5</span><span class="period">.</span>
</h6>
<p id="p-3767">We will use Sage to find the eigenvalues and eigenvectors of a matrix.  Let's begin with the matrix \(A = \left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]
\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2539">
<p id="p-3768">We can find the characteristic polynomial of a matrix \(A\) by writing <code class="code-inline tex2jax_ignore">A.charpoly('lam')</code>.  Notice that we have to give Sage a variable in which to write the polynomial;  here, we use <code class="code-inline tex2jax_ignore">lam</code> though you could just as well use <code class="code-inline tex2jax_ignore">x</code>.</p>
<div class="sagecell-sage" id="sage-100"><script type="text/x-sage">A = matrix(2,2,[1,2,2,1])
A.charpoly('lam')
</script></div>
<p id="p-3769">The factored form of the characteristic polynomial may be more useful since it will tell us the eigenvalues and their multiplicities.  The factor chacteristic polynomial is found with <code class="code-inline tex2jax_ignore">A.fcp('lam')</code>.</p>
<div class="sagecell-sage" id="sage-101"><script type="text/x-sage">A = matrix(2,2,[-3,1,0,-3])
A.fcp('lam')
</script></div>
</li>
<li id="li-2540">
<p id="p-3770">If we only want the eigenvalues, we can use <code class="code-inline tex2jax_ignore">A.eigenvalues()</code>.</p>
<div class="sagecell-sage" id="sage-102"><script type="text/x-sage">A = matrix(2,2,[-3,1,0,-3])
A.eigenvalues()
</script></div>
<p id="p-3771">Notice that the multiplicity of an eigenvalue is the number of times it is repeated in the list of eigenvalues.</p>
</li>
<li id="li-2541">
<p id="p-3772">Finally, we can find eigenvectors by <code class="code-inline tex2jax_ignore">A.eigenvectors_right()</code>.  (We are looking for <em class="emphasis">right</em> eigenvalues since the vector \(\vvec\) appears to the right of \(A\) in the definition \(A\vvec=\lambda \vvec\text{.}\))</p>
<div class="sagecell-sage" id="sage-103"><script type="text/x-sage">A = matrix(2,2,[-3,1,0,-3])
A.eigenvectors_right()
</script></div>
<p id="p-3773">At first glance, the result of this command can be a little confusing to interpret.  What we see is a list with one entry for each eigenvalue.  For each eigenvalue, there is a triple consisting of (i) the eigenvalue \(\lambda\text{,}\) (ii) a basis for \(E_\lambda\text{,}\) and (iii) the multiplicity of \(\lambda\text{.}\)</p>
</li>
<li id="li-2542">
<p id="p-3774">When working with decimal entries, which are called <em class="emphasis">floating point numbers</em> in computer science, we must remember that computers perform only approximate arithmetic. This is a problem when we wish to find the eigenvectors of such a matrix.  To illustrate, consider the matrix \(A=\left[\begin{array}{rr}
0.4 \amp 0.3 \\
0.6 \amp 0.7 \\
\end{array}\right]
\text{.}\)</p>
<ol class="lower-roman">
<li id="li-2543"><p id="p-3775">Without using Sage, find the eigenvalues of this matrix.</p></li>
<li id="li-2544"><p id="p-3776">What do you find for the reduced row echelon form of \(A-I\text{?}\)</p></li>
<li id="li-2545">
<p id="p-3777">Let's now use Sage to determine the reduced row echelon form of \(A-I\text{:}\)</p>
<div class="sagecell-sage" id="sage-104"><script type="text/x-sage">A = matrix(2,2,[0.4,0.3,0.6,0.7])
(A-identity_matrix(2)).rref()
</script></div>
<p id="p-3778">What result does Sage report for the reduced row echelon form?  Why is this result not correct?</p>
</li>
<li id="li-2546">
<p id="p-3779">Because the arithmetic Sage performs with floating point entries is only approximate, we are not able to find the eigenspace \(E_1\text{.}\)  In this next chapter, we will learn how to address this issue.  In the meantime, we can get around this problem by writing the entries in the matrix as rational numbers:</p>
<div class="sagecell-sage" id="sage-105"><script type="text/x-sage">A = matrix(2,2,[4/10,3/10,6/10,7/10])
A.eigenvectors_right()
</script></div>
</li>
</ol>
</li>
</ol></article></section><section class="subsection" id="subsection-62"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.2.5</span> <span class="title">Summary</span>
</h3>
<p id="p-3789">In this section, we developed a technique for finding the eigenvalues and eigenvectors of an \(n\times n\) matrix \(A\text{.}\)</p>
<ul class="disc">
<li id="li-2555"><p id="p-3790">The expression \(\det(A-\lambda I)\) is a degree \(n\) polynomial, known as the characteristic polynomial. The eigenvalues are the roots of the characteristic polynomial \(\det(A-\lambda I) = 0\text{.}\)</p></li>
<li id="li-2556"><p id="p-3791">The set of eigenvectors associated to the eigenvalue \(\lambda\) forms the eigenspace \(E_\lambda =
\nul(A-\lambda I)\text{.}\)</p></li>
<li id="li-2557">
<p id="p-3792">If the factor \((\lambda_j - \lambda)\) appears \(m_j\) times in the characteristic polynomial, we say that the eigenvalue \(\lambda_j\) has multiplicity \(m_j\) and note that</p>
<div class="displaymath">
\begin{equation*}
1 \leq \dim E_{\lambda_j} \leq m_j\text{.}
\end{equation*}
</div>
</li>
<li id="li-2558"><p id="p-3793">If each of the eigenvalues is real and has multiplicity \(1\text{,}\) then we can form a basis for \(\real^n\) consisting of eigenvectors of \(A\text{.}\)</p></li>
<li id="li-2559"><p id="p-3794">We can use Sage to find the eigenvalues and eigenvalues of matrices.  However, we need to be careful working with floating point numbers since floating point arithmetic is only an approximation.</p></li>
</ul></section><section class="exercises" id="exercises-16"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">4.2.6</span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-134"><h6 class="heading"><span class="codenumber">1<span class="period">.</span></span></h6>
<p id="p-3795">For each of the following matrices, find its characteristic polynomial, its eigenvalues, and the multiplicity of each eigenvalue.</p>
<ol class="lower-alpha">
<li id="li-2560"><p id="p-3796">\(A=\left[\begin{array}{rr}
4 \amp -1 \\
4 \amp 0 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2561"><p id="p-3797">\(A=\left[\begin{array}{rrr}
3 \amp -1 \amp 3 \\
0 \amp 4 \amp 0 \\
0 \amp 0 \amp -6
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2562"><p id="p-3798">\(A = \left[\begin{array}{rr}
-2 \amp 0 \\
0 \amp -2 \\
\end{array}\right]
\text{.}\)</p></li>
<li id="li-2563"><p id="p-3799">\(A=\left[\begin{array}{rr}
-1 \amp 2 \\
2 \amp 2 \\
\end{array}\right]
\text{.}\)</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-135"><h6 class="heading"><span class="codenumber">2<span class="period">.</span></span></h6>
<p id="p-3810">Given an \(n\times n\) matrix \(A\text{,}\) an important question <a class="xref" data-knowl="./knowl/question-eigen-basis.html" title="Question 4.1.7">Question 4.1.7</a> asks whether we can find a basis of \(\real^n\) consisting of eigenvectors of \(A\text{.}\)  For each of the matrices in the previous exericse, find a basis of \(\real^n\) consisting of eigenvectors or state why such a basis does not exist.</p></article><article class="exercise exercise-like" id="exercise-136"><h6 class="heading"><span class="codenumber">3<span class="period">.</span></span></h6>
<p id="p-3821">Determine whether the following statements are true or false and provide a justification for your response.</p>
<ol class="lower-alpha">
<li id="li-2580"><p id="p-3822">The eigenvalues of a matrix \(A\) are the entries on the diagonal of \(A\text{.}\)</p></li>
<li id="li-2581"><p id="p-3823">If \(\lambda\) is an eigenvalue of multiplicity \(1\text{,}\) then \(E_\lambda\) is one-dimensional.</p></li>
<li id="li-2582"><p id="p-3824">If a matrix \(A\) is invertible, then \(\lambda=0\) cannot be an eigenvalue.</p></li>
<li id="li-2583"><p id="p-3825">If \(A\) is a \(13\times 13\) matrix, the charasteristic polynomial has degree less than \(13\text{.}\)</p></li>
<li id="li-2584"><p id="p-3826">The eigenspace \(E_\lambda\) of \(A\) is the same as the null space \(\nul(A-\lambda I)\text{.}\)</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-137"><h6 class="heading"><span class="codenumber">4<span class="period">.</span></span></h6>
<p id="p-3839">Provide a justification for your response to the following questions.</p>
<ol class="lower-alpha">
<li id="li-2595"><p id="p-3840">Suppose that \(A\) is a \(3\times 3\) matrix having eigenvalues \(\lambda = -3,3,-5\text{.}\)  What are the eigenvalues of \(2A\text{?}\)</p></li>
<li id="li-2596"><p id="p-3841">Suppose that \(D\) is a diagonal \(3\times 3\) matrix.  Why can you guarantee that there is a basis of \(\real^3\) consisting of eigenvectors of \(D\text{?}\)</p></li>
<li id="li-2597"><p id="p-3842">If \(A\) is a \(3\times 3\) matrix whose eigenvalues are \(\lambda = -1,3,5\text{,}\) can you guarantee that there is a basis of \(\real^3\) consisting of eigenvectors of \(A\text{?}\)</p></li>
<li id="li-2598">
<p id="p-3843">Suppose that the characteristic polynomial of a matrix \(A\) is</p>
<div class="displaymath">
\begin{equation*}
\det(A-\lambda I) = -\lambda^3 + 4\lambda\text{.}
\end{equation*}
</div>
<p class="continuation">What are the eigenvalues of \(A\text{?}\)  Is \(A\) invertible?  Is there a basis of \(\real^n\) consisting of eigenvectors of \(A\text{?}\)</p>
</li>
<li id="li-2599">
<p id="p-3844">If the characteristic polynomial of \(A\) is</p>
<div class="displaymath">
\begin{equation*}
\det(A-\lambda I) = (4 -\lambda)(-2-\lambda)(1-\lambda)\text{,}
\end{equation*}
</div>
<p class="continuation">what is the characteristic polynomial of \(A^2\text{?}\) what is the characteristic polynomial of \(A^{-1}\text{?}\)</p>
</li>
</ol></article><article class="exercise exercise-like" id="exercise-138"><h6 class="heading"><span class="codenumber">5<span class="period">.</span></span></h6>
<p id="p-3857">For each of the following matrices, use Sage to determine its eigenvalues, their multiplicities, and a basis for each eigenspace.  For which matrices is it possible to construct a basis for \(\real^3\) consisting of eigenvectors? <div class="sagecell-sage" id="sage-106"><script type="text/x-sage">
</script></div></p>
<ol class="lower-alpha">
<li id="li-2610"><p id="p-3858"> \(\displaystyle A = \left[\begin{array}{rrr}
-4 \amp 12 \amp -6 \\
4 \amp -5 \amp 4 \\
11 \amp -20 \amp 13 \\
\end{array}\right]\)</p></li>
<li id="li-2611"><p id="p-3859"> \(\displaystyle A = \left[\begin{array}{rrr}
1 \amp -3 \amp 1 \\
-4 \amp 8 \amp -5 \\
-8 \amp 17 \amp -10 \\
\end{array}\right]\)</p></li>
<li id="li-2612"><p id="p-3860">\(\displaystyle A = \left[\begin{array}{rrr}
3 \amp -8 \amp 4 \\
-2 \amp 3 \amp -2 \\
-6 \amp 12 \amp -7 \\
\end{array}\right]\)</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-139"><h6 class="heading"><span class="codenumber">6<span class="period">.</span></span></h6>
<p id="p-3869">There is a relationship between the determinant of a matrix and the product of its eigenvalues.</p>
<ol class="lower-alpha">
<li id="li-2619"><p id="p-3870">We have seen that the eigenvalues of the matrix \(A = \left[\begin{array}{rr}
1 \amp 2 \\
2 \amp 1 \\
\end{array}\right]\) are \(\lambda = 3,-1\text{.}\)  What is \(\det A\text{?}\)  What is the product of the eigenvalues of \(A\text{?}\)</p></li>
<li id="li-2620"><p id="p-3871">Consider the triangular matrix \(A = \left[\begin{array}{rrr}
2 \amp 0 \amp 0 \\
-1 \amp -3 \amp 0 \\
3 \amp 1 \amp -2 \\
\end{array}\right]
\text{.}\)  What are the eigenvalues of \(A\text{?}\)  What is \(\det
A\text{?}\)  What is the product of the eigenvalues of \(A\text{?}\)</p></li>
<li id="li-2621"><p id="p-3872">Based on these examples, what do you think is the relationship between the determinant of a matrix and the product of its eigenvalues?</p></li>
<li id="li-2622">
<p id="p-3873">Suppose the characteristic polynomial is written as</p>
<div class="displaymath">
\begin{equation*}
\det(A-\lambda I) = (\lambda_1-\lambda)(\lambda_2-\lambda)
\ldots (\lambda_n-\lambda)\text{.}
\end{equation*}
</div>
<p class="continuation">By substituting \(\lambda = 0\) into this equation, explain why the determinant of a matrix equals the product of its eigenvalues.</p>
</li>
</ol></article><article class="exercise exercise-like" id="exercise-140"><h6 class="heading"><span class="codenumber">7<span class="period">.</span></span></h6>
<p id="p-3884">Consider the matrix \(A=\left[\begin{array}{rr}
0.5 \amp 0.6 \\
-0.3 \amp 1.4 \\
\end{array}\right]
\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-2631"><p id="p-3885">Find the eigenvalues of \(A\) and a basis for their associated eigenspaces.</p></li>
<li id="li-2632"><p id="p-3886">Suppose that \(\xvec_0=\twovec{11}{6}\text{.}\)  Express \(\xvec_0\) as a linear combination of eigenvectors of \(A\text{.}\)</p></li>
<li id="li-2633">
<p id="p-3887">Define the vectors</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
\xvec_1 \amp {}={} A\xvec_0 \\
\xvec_2 \amp {}={} A\xvec_1 = A^2\xvec_0 \\
\xvec_3 \amp {}={} A\xvec_2 = A^3\xvec_0 \\
\vdots \amp {}={} \vdots
\end{aligned}\text{.}
\end{equation*}
</div>
<p class="continuation">Write \(\xvec_1\text{,}\) \(\xvec_2\text{,}\) and \(\xvec_3\) as a linear combination of eigenvectors of \(A\text{.}\)</p>
</li>
<li id="li-2634"><p id="p-3888">What happens to \(\xvec_k\) as \(k\) grows larger and larger?</p></li>
</ol></article><article class="exercise exercise-like" id="exercise-141"><h6 class="heading"><span class="codenumber">8<span class="period">.</span></span></h6>
<p id="p-3899">Consider the matrix \(A=\left[\begin{array}{rr}
0.4 \amp 0.3 \\
0.6 \amp 0.7 \\
\end{array}\right]\)</p>
<ol class="lower-alpha">
<li id="li-2643"><p id="p-3900">Find the eigenvalues of \(A\) and a basis for their associated eigenspaces.</p></li>
<li id="li-2644"><p id="p-3901">Suppose that \(\xvec_0=\twovec{0}{1}\text{.}\)  Express \(\xvec_0\) as a linear combination of eigenvectors of \(A\text{.}\)</p></li>
<li id="li-2645">
<p id="p-3902">Define the vectors</p>
<div class="displaymath">
\begin{equation*}
\begin{aligned}
\xvec_1 \amp {}={} A\xvec_0 \\
\xvec_2 \amp {}={} A\xvec_1 = A^2\xvec_0 \\
\xvec_3 \amp {}={} A\xvec_2 = A^3\xvec_0 \\
\vdots \amp {}={} \vdots
\end{aligned}\text{.}
\end{equation*}
</div>
<p class="continuation">Write \(\xvec_1\text{,}\) \(\xvec_2\text{,}\) and \(\xvec_3\) as a linear combination of eigenvectors of \(A\text{.}\)</p>
</li>
<li id="li-2646"><p id="p-3903">What happens to \(\xvec_k\) as \(k\) grows larger and larger?</p></li>
</ol></article></section></section></div></main>
</div>
</body>
</html>
